---
layout: 12pt
header-includes:
   - \usepackage{lineno}
   - \linenumbers
   - \usepackage{setspace}
   - \usepackage{sectsty}
   - \doublespacing
   - \usepackage{todonotes}
   - \usepackage[document]{ragged2e}
   - \usepackage{times}
   - \usepackage{enumitem}
bibliography: ~/Dropbox/Bibliography/MicroMeso.bib
csl: components/ecology.csl

## rmarkdown render options
output:
  pdf_document:
    fig_caption: true
    keep_tex: false
fontsize: 12pt
geometry: margin=1in
linkcolor: black
urlcolor: black

---

\textsf{\LARGE{\textbf{Do we need demographic data to forecast the state of plant populations?}}}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}

\vspace{1em}

\textsf{\normalsize{\textbf{Andrew T. Tredennick\textsuperscript{1}\footnote{Corresponding author: E-mail: atredenn@gmail.com}, Mevin B. Hooten\textsuperscript{2,3,4}, and Peter B. Adler\textsuperscript{1}}}}

\vspace{1em}

\textsf{\textit{\footnotesize{\textsuperscript{1}Department of Wildland Resources and the Ecology Center, 5230 Old Main Hill, Utah State University, Logan, Utah 84322, USA; \textsuperscript{2}U.S. Geological Survey, Colorado Cooperative Fish and Wildlife Research Unit, Fort Collins, CO 80523, USA; \textsuperscript{3}Department of Fish, Wildlife, and Conservation Biology, Colorado State University, Fort Collins, CO 80523 USA}; \textsuperscript{4}Department of Statistics, Colorado State University, Fort Collins, CO 80523 USA}}


\allsectionsfont{\normalfont\sffamily\bfseries}
\renewcommand*{\thefootnote}{\arabic{footnote}}
\setcounter{footnote}{0}

\rule{\textwidth}{1pt}


```{r libraris, include=FALSE}
library(ggplot2)
library(plyr)
library(gridExtra)
library(reshape2)
library(xtable)
library(ggmcmc)
```

```{r caching, include=FALSE}
library("methods")
library("knitr")
basename <- "manuscript"
opts_chunk$set(fig.path = paste("components/figure/", basename, "-", sep=""),
               cache.path = paste("components/cache/", basename, "/", sep=""))
opts_chunk$set(cache = 2)
opts_chunk$set(tidy=FALSE, warning=FALSE, message=FALSE, 
               comment = NA, verbose = TRUE, echo=FALSE)

# PDF-based figures
opts_chunk$set(dev='pdf')
```


```{r plot-options, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
               "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

opts_chunk$set(dev='pdf', dev.args=c(version="1.3"))

```

Summary
-------

\begin{enumerate}[label=\textbf{\arabic*}]
        \item Rapid environmental change has generated growing interest in forecasts of future population trajectories. Traditional population models built with detailed demographic observations from one study site can address the impacts of environmental change at particular locations, but are difficult to scale up to the landscape and regional scales relevant to management decisions.
        \item An alternative is to build models using population-level data which are much easier to collect than individual-level data over broad spatial scales.
However, it is unknown whether models built using population-level data adequately capture the effects of density-dependence and environmental forcing that are necessary to generate skillful forecasts.
        \item Here, we test the consequences of aggregating individual responses when forecasting the population states and trajectories of four perennial grass species in a semi-arid grassland in Montana, USA. We parameterized two population models for each species, one based on individual-level data (survival, growth and recruitment) and one on population-level data (percent cover), and compared their forecasting skill and forecast horizons with and without the inclusion of climate covariates. For both models we used Bayesian ridge regression to weight the influence of climate covariates for optimal prediction. 
        \item In the absence of climate effects, we found no significant difference between the forecasting skill of models based on individual-level data and models based on population-level data. Climate effects were weak, but increased forecasting skill for two species. Increases in skill with climate covariates were similar between model types.
        \item For our focal species at this particular location, and using our particular statistical models, percent cover models generated forecasts as skillful as those from a demographic model. We conclude that models based on aggregated individual-level data offer a practical alternative to data-intensive demographic models.
    \end{enumerate}

\textsf{\textbf{Key-words:}} forecasting, climate change, grassland, integral projection model, population model, statistical regularization, ridge regression

Introduction
------------

Perhaps the greatest challenge for ecology in the 21st century is to forecast the impacts of environmental change [@Clark2001; @Petchey2015]. Forecasts require sophisticated modeling approaches that fully account for uncertainty and variability in both ecological process and model parameters [@Luo2011a; but see @Perretti2013a]. The increasing statistical sophistication of population models [@Rees2009] makes them promising tools for predicting the impacts of environmental change on species persistence and abundance. But reconciling the scales at which population models are parameterized and the scales at which environmental changes play out remains a challenge [@Clark2010; @Freckleton2011; @Queenborough2011; @Clark2012]. Most population models are built using demographic data from a single study site because tracking the fates of individuals is so difficult. The resulting models cannot be applied to the landscape and regional scales relevant to decision-making without information about how the estimated parameters respond to spatial variation in biotic and abiotic drivers [@SÃ¦ther2007]. The limited spatial extent of individual-level demographic datasets constrains our ability to use population models to address applied questions about the consequences of climate change.

Aggregate measures of population status, rather than individual performance, offer an intriguing alternative for modeling populations [@Clark2004; @Freckleton2011]. Population-level data cannot provide inference about demographic mechanisms, but might be sufficient for modeling future population states, especially because such data are feasible to collect across broad spatial extents [e.g., @Queenborough2011]. The choice between individual and population-level data involves a difficult trade-off: while individual-level data are necessary for mechanistic models, population-level data enable models that can be applied over greater spatial and temporal extents. An open question is how much forecasting skill is lost when we build models based on population rather than individual-level data.

To date, most empirical population modelers have relied on individual-level data, with few attempts to capitalize on population-level measures. An important exception was an effort by @Taylor2004 to model the population growth rate of an invasive species to identify the best strategies for invasion control. They used a "density-structured" model where the state variable is a discrete density state rather than a continuous density measure. Such models do not require individual-level demographic data and can adequately describe population dynamics. Building on @Taylor2004, @Freckleton2011 showed that density-structured models compare well to continuous models in theory, and @Queenborough2011 provide empirical evidence that density-structured models are capable of reproducing population dynamics at landscape spatial scales, even if some precision is lost when compared to fully continuous models. However, previous tests of density-structured models have yet to assess their ability to forecast out-of-sample observations, and they have not included environmental covariates, which are necessary to forecast population responses to climate change.

Addressing climate change questions with models fit to population-level data is potentially problematic. Population growth (or decline) is the outcome of demographic processes such as survival, growth, and recruitment that occur at the level of individual plants. Climate can affect each demographic process in unique, potentially opposing, ways [@Dalgleish2011]. These unique climate responses may be difficult to resolve in statistical models based on population-level data where demographic processes are not identifiable. Futhermore, models based on aggregated data may reflect short-term effects of one vital rate more than others whose importance may only emerge over the long-term. For example, a one-year change in a plant species' cover or biomass might reflect individual growth or shrinkage, whereas the long-term trajectory of the population might be more influenced by recruitment. The same is true for density dependence: intraspecific density depedence may act most strongly on vital rates, like recruitment, that are difficult to identify from population-level data. If density dependence and/or important climate effects are missed because of the aggregation inherent in in population-level data, then population models built with such data will make uninformative or unreliable forecasts.

We compared the forecasting skill of statistical and population models based on aggregated, population-level data with the skill of models based on individual-level data. We used a demographic dataset that tracks the fates of individual plants from four species over 14 years to build two kinds of single-species population models, traditional models using individual growth, survival, and recruitment data and alternative models based on basal cover. We simulated the models to answer two questions motivated by the fact that the effects of intraspecific competition (density dependence) and interannual weather variability act at the level of the individual [@Clark2011b].
First, can population models fit using aggregated individual-level data (percent cover) adequately capture density dependence to produce forecasts as skillful as those from models fit to demographic data? 
Second, can population models fit using aggregated data adequately capture the influence of climate on population growth and, in turn, produce forecasts as skillful as those from models fit to demographic data? 


Materials and Methods
---------------------
### Study site and data
Our demographic data come from a northern mixed grass prairie at the Fort Keogh Livestock and Range Research Laboratory near Miles City, Montana, USA ($46^{\circ}$ 19' N, $105^{\circ}$ 48' W). The dataset is available on Ecological Archives[^link] [@Anderson2011], and interested readers should refer to the metadata for a complete description. The site is 800 m above sea level and mean annual precipitation (1878-2009) is 334 mm, with most annual precipitation falling from April through September. The community is grass-dominated, and we focused on the four most abundant grass species: \emph{Bouteloua gracilis} (BOGR), \emph{Hesperostipa comata} (HECO), \emph{Pascopyrum smithii} (PASM), and \emph{Poa secunda} (POSE) (Fig. 1). *B. gracilis* is a warm-season perennial grass, whereas *H. comata*, *P. smithii*, and *Poa secunda* are cool-season perennial grasses. The growing season begins in early spring (typically in April) and lasts through mid-summer (typically in June).

[^link]: http://esapubs.org/archive/ecol/E092/143/

From 1932 to 1945, individual plants were identified and mapped annually in 44 1-$\text{m}^2$ quadrats using a pantograph. The quadrats were distributed among six pastures, each assigned a grazing treatment of light (1.24 ha/animal unit month), moderate (0.92 ha/aum), and heavy (0.76 ha/aum) stocking rates (two pastures per treatment). In this analysis, we accounted for potential differences among the grazing treatments, but do not focus on grazing$\times$climate interactions. The annual maps of the quadrats were digitized and the fates of individual plants tracked and extracted using a computer program [@Lauenroth2008; @Chu2014a]. The permanent quadrats have not been relocated, but their distribution in six different pastures means the data represent a broad spatial distribution for the study area. Daily climate data are available for the duration of the data collection period (1932 - 1945) from the Miles City airport, Wiley Field, 9 km from the study site.

We modeled each grass population based on two levels of data: individual and quadrat. The individual data are the "raw" data. For the quadrat-level data we simply sum individual basal cover for each quadrat by species. This is equivalent to a near-perfect census of quadrat percent cover because measurement error at the individual-level is small [@Chu2014]. Based on these two datasets of 13 year-to-year transitions, we can compare population models built using individual-level data and aggregated, quadrat-level data. At the individual level, we explicitly model three vital rates: growth, survival, and recruitment. At the quadrat level, we model population growth as change in percent cover of quadrats with non-zero cover in year *t* and in year *t-1*, ignoring within-quadrat extirpation and colonization events because they are very rare in our time series ($N=16$ and $N=13$, respectively, across all species). Sample sizes for each species and vital rate model are shown in Table 1. 

All R code and data necessary to reproduce our analysis is archived on GitHub as release v1.0[^revnote] (http://github.com/atredennick/MicroMesoForecast/releases). We have also deposited the v1.0 release on Dryad (*link here after acceptance*).

[^revnote]: *Note to reviewers*: so that v1.0 will be associated with the published version of the manuscript, we have released v0.2 to be associated with this review version.

### Stastical models of vital rates
At both levels of inference (individual and quadrat), the building blocks of our population models are vital rate regressions. For individual-level data, we fit regressions for survival, growth, and recruitment for each species. At the quadrat-level, we fit a single regression model for population growth. We describe the statistical models separately because they required different approaches. For both model types, we fit vital rate models with and without climate covariates. Models with climate effects contain five climate covariates that we chose \emph{a priori} based on previous model selection efforts using these data (Chu et al. *in press*) and expert advice (Lance Vermeire, *personal communication*): "water year" precipitation at \emph{t}-2 (lagppt); April through June precipitation at \emph{t}-1 and \emph{t} (ppt1 and ppt2, respectively) and April through June temperature at \emph{t}-1 and \emph{t} (TmeanSpr1 and TmeanSpr2, respectively), where \emph{t}-1 to *t* is the transition of interest. We also include interactions among same-year climate covariates (e.g., ppt1 $\times$ TmeansSpr1), resulting in a total of seven climate covariates.

We fit all models using a hierarchical Bayesian approach. We focus on the main process and the model likelihood in what follows (full model descriptions are in the Supporting Information). For the likelihood models, $\textbf{y}^X$ is always the relevant vector of observations for vital rate *X* (*X* = *S*, *G*, *R*, or *P*) for survival, growth, recruitment, or population growth). For example, $\textbf{y}^S$ is a vector of 0s and 1s indicating whether a genet survives from *t* to *t+1*, or not, for all observation years and quadrats. All model parameters are species-specific, but we omit subscripts for species in model descriptions below to reduce visual clutter. For brevity, we only describe models with climate covariates included, but models without climate covariates are simply the models described below with the climate effects removed.

#### Vital rate models at the individual level
We used logistic regression to model the probability that genet *i* in quadrat *q* survives from time *t* to *t*+1 ($s_{i,q,t}$):

\vspace{-3em}
\begin{align}
y_{i,q,t}^{S} &\sim \text{Bernoulli}(s_{i,q,t}), \\
\text{logit}(s_{i,q,t}) &= \beta_{0,t} + \beta_{s,t}x_{i,q,t} + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c + \beta_{d,1} w_{i,t} + \beta_{d,2} (x_{i,q,t}w_{i,q,t}),
\end{align}
\vspace{-3em}

where $x_{i,q,t}$ is the log of genet *i* basal area at time *t*, $\beta_{0,t}$ is a year specific intercept, $\beta_Q$ is the random effect of quadrat group location, $\beta_{s,t}$ is the year-specific slope parameter for size, **z** is a vector of *p* climate covariates specific to year *t*, $\boldsymbol{\beta}_c$ is a vector of fixed climate effects of length *p*, $\beta_{d,1}$ is the effect of intraspecific crowding experienced by the focal genet at time *t* ($w_{i,q,t}$), and $\beta_{d,2}$ is a size by crowding ($x_{i,q,t}w_{i,q,t}$) interaction effect. 

We follow the approach of @Chu2015 to estimate crowding, assuming that the crowding experienced by a focal genet depends on distance to each neighbor genet and the neighbor's size, _u_:

\begin{equation}
w_{i,q,t} = \sum_k e^{-\delta d_{ik,q,t}^{2}}u_{k,q,t}.
\end{equation}

In the above, $w_{i,t}$ is the crowding that genet _i_ in year _t_ experiences from conspecific neighbors in quadrat *q*. The spatial scale over which conspecific neighbors exert influence on any genet is determined by $\delta$. The function is applied for all _k_ conspecific genets that neighbor the focal genet at time _t_, and $d_{ik,q,t}$ is the distance between genet _i_ and conspecific genet _k_ in quadrat *q*. We use regression-specific (survival and growth) $\delta$ values estimated by @Chu2015.

We modeled growth as a Gaussian process describing log genet size ($y_{i,q,t+1}^{G}$) at time $t+1$ in quadrat *q* as a function of log size at time $t$ and climate covariates:

\vspace{-3em}
\begin{align}
y_{i,q,t+1}^G &\sim \text{Normal}(\mu_{i,q,t+1}, \sigma^2_{x_{i,q,t+1}}\textbf{I}), \\
\mu_{i,q,t+1} &= \beta_{0,t} + \beta_{s,t}x_{i,q,t} + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c + \beta_{d,1} w_{i,q,t} + \beta_{d,2} (x_{i,q,t}w_{i,q,t}),
\end{align}
\vspace{-3em}

where $\mu_{i,q,t+1}$ is log of genet *i*s predicted size at time *t* + 1, and all other parameters are as described for the survival regression. We capture non-constant error variance in growth by modeling the variance in the growth regression ($\sigma^2_{x{i,q,t+1}}$) as a nonlinear function of predicted genet size:

\vspace{-3em}
\begin{align}
\sigma^2_{x_{i,q,t+1}} = a \, \text{exp}[b \times \mu_{i,q,t+1}],
\end{align}
\vspace{-3em}

where $\mu_{i,q,t+1}$ is log of predicted genet size predicted from the growth regression (Eq. 4), and *a* and *b* are constants.

Our data allows us to track new recruits, but we cannot assign a specific parent to new genets. 
Therefore, we model recruitment at the quadrat level.
We assume the number of individuals, $y^{R}_{q,t+1}$, recruiting at time $t+1$ in quadrat *q* follows a negative binomial distribution:

\vspace{-3em}
\begin{align}
y^{R}_{q,t+1} \sim \text{NegBin}(\lambda_{q,t+1},\phi),
\end{align}
\vspace{-3em}

where $\lambda$ is the mean intensity and $\phi$ is the size parameter. We define $\lambda$ as a function of quadrat composition and climate in the previous year:

\vspace{-3em}
\begin{align}
\lambda_{q,t+1} = \tilde{c}_{q,t} \, \text{exp}\left(\beta_{0,t} + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c + \beta_{d}\sqrt{\tilde{c}_{q,t}}\right),
\end{align}
\vspace{-3em}

where $\tilde{c}_{q,t}$ is effective cover ($\text{cm}^2$) of the focal species in quadrat *q* at time *t*, and all other terms are as in the survival and growth regressions.
Effective cover is a mixture of observed cover (*c*) in the focal quadrat (*q*) and the mean cover across the entire group ($\bar{c}$) of *Q* quadrats in which *q* is located:

\vspace{-3em}
\begin{align}
\tilde{c}_{q,t} = pc_{q,t} + (1-p)\bar{c}_{Q,t},
\end{align}
\vspace{-3em}

where $p$ is a mixing fraction between 0 and 1 that is estimated when fitting model.


#### Population model at the quadrat level
The statistical approach used to model aggregated data depends on the type of data collected. We have percent cover data, which can easily be transformed to proportion data in our case because plant areas were scaled by plot area. An obvious choice for fitting a linear model to proportion data is beta regression because the support of the beta distribution is (0,1), which does not include true zeros or ones. However, when we used fitted model parameters from a beta regression in a quadrat-based population model, the simulated population tended toward 100% cover for all species. We therefore chose a modeling approach based on a truncated log-normal likelihood. The model for quadrat cover change from time $t$ to $t+1$ is

\vspace{-3em}
\begin{align}
y_{q,t+1}^{P} &\sim \text{LogNormal}(\mu_{q,t+1}, \sigma^2)_{0}^{1}, \\
\mu_{q,t+1} &= \beta_{0,t} + \beta_{s,t}x_{q,t} + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c,
\end{align}
\vspace{-3em}

where $\mu_{q,t+1}$ is the log of proportional cover in quadrat *q* at time $t+1$, and all other parameters are as in the individual-level growth model (Eq. 4) except that *x* now represents log of proportional cover. The log normal likelihood includes a truncation (subscript 0, superscript 1) to ensure that predicted values do not exceed 100% cover. 

### Model fitting and statistical regularization
####  Model fitting
Our Bayesian approach to fitting the vital rate models required choosing appropriate priors for unknown parameters and deciding which, if any, of those priors should be hierarchical. For each species, we fit yearly size effects and yearly intercepts hierarchically, where year-specific coefficients were drawn from global distributions representing the mean size effect and intercept. Quadrat random effects were also fit hierarchically, with quadrat offsets being drawn from distributions with mean zero and a shared variance term (independent Gaussian priors). Climate effects were modeled as independent covariates whose prior distributions were optimized for prediction using statistical regularization (see **Statistical regularization: Bayesian ridge regression** below).

All of our analyses (model fitting and simulating) were conducted in R [@R2013]. We used the 'No-U-Turn' Hamiltonian Monte Carlo sampler in Stan [@stan2014]  to estimate the posterior distributions of model parameters using the package `rstan` [@rstan2014]. We obtained posterior distributions for all model parameters from three parallel MCMC chains run for 1,000 iterations after discarding an initial 1,000 iterations. Such short MCMC chains are possible because the Stan sampler reduces the number of iterations needed to achieve convergence. We assessed convergence visually and checked that scale reduction factors for all parameters were less than 1.1. There were six instances where the scale reduction factor for a particular parameter was greater than 1.1. In those cases, we checked the traceplots of the violating parameter and discovered that one chain, out of three, was poorly behaved. Therefore, we removed that chain from the analysis, leaving two well-mixed and converged chains for those six parameters. For the purposes of including parameter uncertainty in our population models, we retained the final 1,000 iterations from each of the three MCMC chains to be used as randomly drawn values during population simulation. We report the posterior mean, standard deviation, and 95% Bayesian Credible Intervals for every parameter of each model for each species in the Supporting Information (Tables S5-S20).

#### Statistical regularization: Bayesian ridge regression
For models with climate covariates, our objective is to model the response of our focal grass species to interannual variation in climate, even if those responses are weak.
Therefore, we avoid selecting among models with all possible combinations of climate covariates, and instead use Bayesian ridge regression to regulate, or constrain, the posterior distributions of each climate covariate [@Gerber2015; @Hooten2015].
Ridge regression is a specific application of statistical regularization that seeks to optimize model generality by trading off bias and variance.
As the name implies, statistical regularization involves the use of a regulator that constrains an optimization.
The natural regulator in a Bayesian application is the prior on the coefficient of interest.
Each of our statistical models includes the effects of climate covariates via the term $\textbf{z}'_t \boldsymbol{\beta}_c$ with prior $\boldsymbol{\beta}_c \sim \text{Normal}(\boldsymbol{\mu}_{\beta_c}, \sigma_{\beta_c}^2\textbf{I})$.
Because we standardized all climate covariates to have mean zero and variance one, we set $\boldsymbol{\mu}_{\beta_c} = 0$ and let $\sigma_{\beta_c}^2$ serve as the regulator that shrinks covariates toward zero -- the smaller the prior variance, the more the posteriors of $\boldsymbol{\beta}_c$ are shrunk toward zero, and the stronger the penalty [@Hooten2015].

To find the optimal penalty (i.e., optimal value of the hyperparameter $\sigma_{\beta_c}^2$), we fit each statistical model with a range of values for $\sigma_{\beta_c}^2$ and compared predictive scores from leave-one-year-out cross-validation.
We performed the grid search over 24 values of $\sigma_{\beta_c}^2$, ranging from $\sigma_{\beta_c}^2 = 0.01$ to $\sigma_{\beta_c}^2 = 2.25$.
For each statistical model and each species, we fit $13\times24=312$ iterations of the model fitting algorithm to search $\sigma_{\beta_c}^2$ for the optimal value (13 years to leave out for cross-validation and 24 values of $\sigma_{\beta_c}^2$) -- a total of 4,992 model fits.
We calculated the log pointwise predictive density (*lppd*) to score each model's ability to predict the left-out data [@Gelman2014].
Thus, for training data $y_{train}$ and held-out data $y_{hold}$ at a given value of  $\sigma_\theta^2$ across all MCMC samples $s=1,2,...,S$ and all hold outs of data from year *t* to year *T*, and letting $\theta$ represent all unknowns, *lppd* is

\vspace{-3em}
\begin{align}
\text{lppd}_{\text{CV}} = \sum_{t=1}^T \text{log}_e \int [y_{t,hold}|\theta][\theta|y_{train}]d\theta,
\end{align}
\vspace{-3em}

and computed as

\vspace{-3em}
\begin{align}
\sum_{t=1}^T \text{log}_e \left(\frac{1}{S} \sum^S_{s=1}(y_{t,hold}|\theta_{ts})  \right).
\end{align}
\vspace{-3em}

We chose the optimal prior variance for each species-statistical model combination as the one that produced the highest *lppd* and then fit each species-statistical model combination using the full data set for each species and the optimal prior variance.
We calculated the *lppd* from posterior samples using the algorithm from @Vehtari2016.

### Population models
Using samples from the posterior distribution of the vital rate statistical models, it is straightforward to simulate the population models. We used an Integral Projection Model (IPM) to simulate populations based on individual-level data [@Ellner2006] and a quadrat-based version of an individually-based model (Quadrat-Based Model, QBM) to simulate populations based on quadrat-level data. We describe each in turn.

#### Integral projection model
We use a stochastic IPM [@Rees2009] to simulate our focal populations based on the vital rate regressions described above. In all simulations, we ignore the random year effects so that interannual variation is driven solely by climate. We fit the random year effects in the vital rate regressions to avoid over-attributing variation to climate covariates. Our IPM follows the specification of @Chu2015 where the population of species _j_ is $n(u_{j},t)$, giving the density of sized-_u_ genets at time _t_. Genet size is on the natural log scale, so that $n(u_{j},t)du$ is the number of genets whose area (on the arithmetic scale) is between $e^{u_{j}}$ and $e^{u_{j}+du}$. The function for any size _v_ at time $t+1$ is

\vspace{-3em}
\begin{align}
n(v_{j},t+1) = \int_{L_{j}}^{U_{j}} k_{j}(v_{j},u_{j},\bar{w_{j}}(u_{j}))n(u_{j},t)du_{j},
\end{align}
\vspace{-3em}

where $k_{j}(v_{j},u_{j},\bar{w_{j}})$ is the population kernel that describes all possible transitions from size $u$ to $v$ and $\bar{w_{j}}$ is a scalar representing the average intraspecific crowding experienced by a genet of size $u_j$ and species $j$. The integral is evaluated over all possible sizes between predefined lower (_L_) and upper (_U_) size limits that extend beyond the range of observed genet sizes.

The IPM is spatially-implicit, thus, we cannot calculate neighborhood crowding for specific genets ($w_{ij}$). Instead, we use an approximation ($\bar{w_{j}}$) that captures the essential features of neighborhood interactions [@Adler2010]. This approximation relies on a 'no-overlap' rule for conspecific genets to approximate the overdispersion of large genets in space [@Adler2010].

The population kernel is defined as the joint contributions of survival (_S_), growth (_G_), and recruitment (_R_):

\vspace{-3em}
\begin{align}
k_{j}(v_{j},u_{j},\bar{w_{j}}) = S_j(u_j, \bar{w_{j}}(u_{j}))G_j(v_{j},u_{j},\bar{w_{j}}(u_{j})) + R_j(v_{j},u_{j},\bar{w_{j}}),
\end{align}
\vspace{-3em}

which means we are calculating growth (_G_) for individuals that survive (_S_) from time _t_ to _t+1_ and adding in newly recruited (_R_) individuals of an average sized one-year-old genet for the focal species. Note the _S_, _G_, and _R_ are incorporated in the IPM using the fitted vital rate regressions. Our statistical model for recruitment (_R_, described above) returns the number of new recruits produced per quadrat. Following previous work [@Adler2012; @Chu2015], we assume that fecundity increases linearly with size ($R_j(v_{j},u_{j},\bar{w_{j}}) = e^{u_j}R_j(v_{j},\bar{w_{j}})$) to incorporate the recruitment function in the spatially-implicit IPM.

We used random draws from the final 1,000 iterations, thinned by 10, from each of three MCMC chains for each vital rate regression to carry-through parameter uncertainty into our population models. At each time step, we randomly selected climate covariates from one of the 14 observed years. Then, we drew the full parameter set (climate effects and density-dependence fixed effects) from a randomly selected MCMC iteration. Relatively unimportant climate covariates (those that broadly overlap 0) will have little effect on the mean of the simulation results, but can contribute to their variation. Our focus was on the contribution of density dependence and climate covariates to population states, thus we set the random year effects and the random group effects to zero. 

#### Quad-based model
To simulate our quad-based model (QBM), we iterate the quadrat-level statistical model (Eqs. 9-10). We use the same approach for drawing parameter values as described for the IPM. After drawing the appropriate parameter set, we calculate the mean response (log cover at *t+1* is $\mu_{t+1}$) according to Eq. 10. We make a random draw from a [0,1] truncated lognormal distribution with mean equal to $\mu_{t+1}$ from Eq. 10 and the variance estimate from the fitted model. We project the model forward by drawing a new parameter set (unique to climate year and MCMC iteration) at each timestep. As with the IPM, random year effects are ommitted in our simulations.

### Model validation
To test each model's ability to forecast population states, we made out-of-sample predictions using leave-one-year-out cross validation. For both levels of modeling and for models with and without climate covariates, we fit the vital rate models using observations from all years except one, and then used those fitted parameters in the population models to perform a one-step-ahead forecast for the year whose observations were withheld from model fitting. Within each observation year, several quadrats were sampled. We made predictions for each observed quadrat in each focal year, initializing each simulation with cover in the quadrat the previous year. Because we were making quadrat-specific predictions, we incorporated the group random effect on the intercept for both models. We repeated this procedure for all 13 observation years, making 100 one-step-ahead forecasts for each quadrat-year combination with parameter uncertainty included via random draw from the MCMC chain as described above. Year-specific intercepts for left-out data were drawn from the posterior distribution of the mean intercept. Thus, for some future year *T*, $\beta_0,T \sim \text{Normal}(\beta_0, \sigma_{\beta_0})$. 

This cross-validation procedure allowed us to compare accuracy and precision of the two modeling approaches (IPM versus QBM) with and without climate covariates. We first calculated the median predicted cover across the 100 simulations for each quadrat-year and then calculated forecast skill as the correlation ($\rho$) between forecasts and observations. We calculated forecast error as mean absolute error (MAE) between forecasts and observations. We compared $\rho$ and MAE between model types and within model types between models with and without climate covariates using one-sided *t* tests with adjusted degrees of freedom following @Wilcox2009 and standard errors calculated using the HC4 estimator of @Cribari-Neto2004. Statistical tests were conducted using algorithms from @Ye2015a.

### Forecast horizons
An important feature of any forecasting model is the rate at which forecast skill declines as the time between an observation and a forecast increases; the so-called ecological forecast horizon [@Petchey2015].
To assess the forecast horizons of our models, we initiate the forecast model with the population state at some time *t* and make sequential forecasts of the population at times $t+1, t+2, \dots, t+T$ where *T* is the maximum number of years between the initial year and the final year of our observations.
For example, if we initialize the forecast model with percent cover in 1940, we are able to make five forecasts up to the year 1945.
Forecast models are not re-initialized with observations between years.
Thus, in our current example, the model forecast for percent cover in 1941 has a forecast horizon of one year, the forecast in 1942 has a forecast horizon of two years, and so on.
We performed these simulations for all model types (IPM with/without climate; QBM with/without climate) using mean parameter values for all possible initial years.
For a given forecast horizon, we averaged the correlation between forecasts and observations.
Note that these forecasts are all made using in-sample data because we used model fits from the full data set.
Nonetheless, these simulations offer insight into the differences among model forecast horizons.


Results
-------
The IPM and QBM generated one-step-ahead forecasts of similar skill for out-of-sample observations, with an average correlation between predictions and observations ($\rho$) of 0.72 across all models and species (Fig. 2).
Without climate covariates, the accuracy of forecasts from the IPM were not statistically greater than the accuracy of forecasts from the QBM (Fig. 2) and overall error was similar (mean absolute error; Fig. S1, Supporting Information).
With climate covariates, the best out-of-sample predictive model (highest *lppd*) for each species and vital rate typically resulted from highly constrained priors on the climate effects (Fig. S2, Supporting Information).
Thus, the posterior distributions of climate effects included in our models overlapped zero and generally shrunk toward zero, though for some species-vital rate combinations, important effects (80% credible interval does not include zero) did emerge (Fig. 3). 

Despite the weak climate effects, including climate covariates did increase the accuracy of forecasts for two species: *B. gracilis* and *Poa secunda* (Fig. 2).
In no case did including climate covariates significantly decrease forecast skill (Table S21), despite small changes in the mean skill (Fig. 2)
Only for *B. gracilis* were the skill increases significant for the IPM ($t_{(279)}$ = 1.70, *P* = 0.045) and the QBM ($t_{(279)}$ = 1.80, *P* = 0.037).
Similarly, forecast error decreased significantly with the inclusion of climate covariates for the *B. gracilis* IPM ($t_{(280)}$ = -3.72, *P* = 0.029) and QBM ($t_{(280)}$ = -3.34, *P* < 0.0001), and for the *Poa secunda* IPM ($t_{(196)}$ = -1.90, *P* < 0.0001) and QBM ($t_{(196)}$ = -2.47, *P* = 0.007) (Fig. S2, Supporting Information).
IPM forecasts were significantly more accurate than the QBM in only one case (Fig. 2): forecast accuracy of *P. smithii* percent cover from an IPM with climate covariates was greater than the accuracy from the QBM with climate covariates ($t_{(215)}$ = 1.92, *P* = 0.028).
However, including climate covariates in the IPM did not significantly increase forecast skill for *P. smithii* (Fig. 2).
Results from all pairwise statistical tests are shown in Table S22 of the Supporting Information.

With climate covariates included, the accuracy of both models' forecasts declined as the forecast horizon increased, but they did so at similar rates (Fig. 4).
The only exception is for *Poa secunda*, where QBM forecast accuracy remained steady as the forecast horizon increases, whereas IPM forecast accuracy declined (Fig. 4).


Discussion
----------
Population models built using individual-level data provide inference on demographic processes, but they can only forecast future population states across the (typically limited) spatial extent of the observations. 
Population-level data are much easier to collect across broad spatial extents, so models built using such data offer an appealing alternative to traditional population models [@Queenborough2011]. 
However, density-structured models rely on the aggregation of individual-level data. 
Given that individuals, not populations, respond to intraspecific competition and weather [@Clark2011b], can models based on population-level metrics generate forecasts that are as skillful as those generated from models based on individual-level data? Are models based on population-level metrics as sensitive to climate forcing as models based on individual-level data? 

Our comparison of a traditional, demographic population model without environmental forcing (the IPM) to an equivalent model inspired by density-structured models (the QBM) showed that, generally, IPM forecasts of out-of-sample plant population states were no more accurate than forecasts from the QBM (Fig. 2; `no-climate' bars).
We expected the IPM to out-perform the QBM because the IPM includes more mechanistic detail on the perennial plant life cycle, but this was not the case, at least when we ignored environmental forcing.
Such a finding confirms theoretical [@Freckleton2011] and empirical work [@Taylor2004; @Queenborough2011] showing that density-structured models can be useful surrogates for demographic models when the goal is to estimate or forecast population states over large spatial extents.

While the models did not differ in forecast accuracy when density-dependence was the only driver of population dynamics, we expected the inclusion of environmental forcing to reveal more differences between the models.
We expected the IPM to outperform the QBM when we included climate covariates because interannual variation in weather can affect vital rates in different ways [@Dalgleish2011].
Thus, estimates of climate effects on plant population growth may be biased or non-identifiable when the underlying statistical model is fit using population-level data that integrates over the potentially unique climate responses of individual vital rates.
However, we found that IPM forecast accuracy was only significantly higher than the QBM for one species, *P. smithii* (Fig. 2, `climate' bars).
That the IPM outperformed the QBM with climate covariates included for *P. smithii* is a moot point, however, because including the climate covariates in the IPM did not increase forecast accuracy over an IPM without climate covariates (Fig. 2).


<!---
The equivalency of the IPM and QBM forecasts stems from the  (Fig. 3).
If climate effects on vital rates are weak, then models based on percent cover or density should fair well compared to models based on individual-level data as long as density dependence is adequately estimated (see Fig. 2 and Freckleton et al. 2011).

Our naive expectation was that a single, relatively important climate effect in a vital rate regression would cause a discernable difference between IPM and QBM forecast skill because individual-level responses may be less identifiable from percent cover data [@Clark2012].
We actually found the opposite.
Survival or recruitment regressions for *B. gracilis*, *H. comata*, and *P. smithii* all included at least one relatively important climate effect, which we *a posteriori* defined as a standardized coefficient whose 80% credible interval does not overlap zero (Fig. 3).
Yet, only the forecast skill for *Poa secunda* differed between the IPM and QBM (Fig. 2).
Our explanation is that while at least one vital regression for the other three species included a relatively strong climate effect, only *Poa secunda* had a vital rate regression with several smaller climate effects all trending in the same direction (Fig. 3).
Thus, it appears that the estimation of several small but consistent effects, rather than a single relatively large effect, can lead to increased forecast skill.

The higher accuracy of the IPM with climate covariates for *Poa secunda*  highlights the advantage of contemporary modeling and variable selection approaches such as ridge regression and LASSO over techniques that would exclude "non-significant" effects from final models.
Ridge regression allows researchers to retain covariates whose effects may be difficult to identify in noisy data or short time series.
This is especially important when forecasting the impacts of climate change, where it is important to include to effects of forcing variables (e.g., temperature and precipitation) even of such effects are difficult to identify.
If a species is truly unresponsive to a given climate variable, statistical regularization techniques will shrink the mean and variance of a covariate estimate toward zero [@Hooten2015].
Of course, no matter what model selection approach is adopted, a critical step is identifying the appropriate candidate covariates, which we attempted to do based on our knowledge of this semi-arid plant community.
However, the climate covariates we chose required aggregating daily weather data over discrete time periods.
It is possible that we did not choose the optimal time periods over which to aggregate.
New methods using functional linear models (or splines) may offer a data-driven approach for identifying the appropriate time periods over which to aggregate to produce a tractable set of candidate climate variables [@Teller2016].

We also expected IPM forecast accuracy to decline at a lower rate than the QBM as the forecast horizon increased.
In principle, more mechanistic models should produce better predictions, especially under novel conditions [@Evans2012b; @Schindler2015b].
In our case, the IPM explicitly models the influence of weather on recruitment and survival, effects that may be poorly represented in the QBM because recruitment and survival mainly affect small plants that contribute little to year-to-year changes in percent cover.
Over time, of course, the addition and subtraction of small plants can have large effects on population growth, so explicitly modeling these effects could contribute to a longer forecast horizon. 
However, we found no evidence for a difference between the IPM and QBM forecast horizons (Fig. 4). Similar forecast horizons should be expected if both models adequately capture density dependence and environmental forcing, as is the case for our models (Fig. 2).

In conclusion, we found that models based on individual-level demographic data generally failed to generate more skillful population forecasts than models based on population-level data.
This finding runs counter to our expectations, but is consistent with recent theoretical [@Freckleton2011] and empirical work [@Queenborough2011].
However, we did achieve more skillful forecasts from the IPM with climate covariates for one species, *Poa secunda*, that appears to respond consistently to several climate variables.
Thus, we conclude that models based on population-level data, rather than individual-level data, may be adequate for forecasting the state of plant populations for species that do not respond consistently or strongly to climate.
Unfortunately, our analysis, where climate effects were relatively unimportant in vital rate regressions, did not allow us to sufficiently test our prediction that individual-level data is neccessary to generate skillful forecasts if different vital rates respond to climate in unique, potentially opposing, ways.
Nonetheless, our results are encouraging for the use of easy-to-collect population-level data for forecasting the state of plant populations.
Our methodological approach could also potentially be used for backcasting paleoclimate and paleoecological aggregates such as pollen counts based on lake sediments [e.g., @Paciorek2009]
--->

Acknowledgments
---------------
This work was funded by the National Science Foundation through a Postdoctoral Research Fellowship in Biology to ATT (DBI-1400370), award MSB-1241856 to MBH, and a CAREER award to PBA (DEB-1054040). We thank the original mappers of the permanent quadrats in Montana and the digitizers in the Adler lab, without whom this work would not have been possible. Informal conversations with Stephen Ellner, Giles Hooker, Robin Snyder, and a series of meetings between the Adler and Weecology labs at USU sharpened our thinking. Brittany Teller provided comments that improved our manuscript. Compute, storage and other resources from the Division of Research Computing in the Office of Research and Graduate Studies at Utah State University are gratefully acknowledged. Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. government.

\pagebreak{}


Tables
------
\begin{table}[ht]
\centering
\caption{Description of data. The observations span 13 year-to-year transitions.} 
\begin{tabular}{llrr}
  \hline
Species & Vital Rate Model & Num. Obs. & Num. Quadrats\\ 
  \hline
  \emph{B. gracilis} & Growth & 5670 & 29 \\ 
       & Survival & 10102 & 33 \\ 
       & Recruitment & 304 & 33 \\ 
       & Percent cover & 281 & 29 \\ 
  \rule{0pt}{3ex} \emph{H. comata} & Growth & 1990 & 16 \\ 
       & Survival & 3257 & 18 \\ 
       & Recruitment & 304 & 18 \\ 
       & Percent cover & 171 & 17 \\ 
  \rule{0pt}{3ex} \emph{P. smithii} & Growth & 8052 & 19 \\ 
       & Survival & 11344 & 19 \\ 
       & Recruitment & 304 & 19 \\ 
       & Percent cover & 217 & 19 \\ 
  \rule{0pt}{3ex} \emph{Poa secunda} & Growth & 3018 & 18 \\ 
       & Survival & 4650 & 18 \\ 
       & Recruitment & 304 & 18 \\ 
       & Percent cover & 197 & 18 \\ 
   \hline
\end{tabular}
\end{table}


<!---
\begin{table}[ht]
\centering
\caption{Accuracy (mean absolute error, MAE) and precision (90\% Distance) 
                  of out of sample predictions. Forecasts were made without random 
                  year effects; only climate covariates could explain year-to-year 
                  variation. 90\% Distance refers to the average distance between the 
                  upper and lower 90th percentiles of the 100 predicted values for 
                  each quadrat-year combination.} 
\begin{tabular}{llrrr}
  \hline
Species & Model & MAE & 90\% Distance & Mean Obs. Cover \\ 
  \hline
BOGR & IPM & 4.61 & 22.41 & 8.26 \\ 
  BOGR & QBM & 4.06 & 29.18 & 8.26 \\ 
  HECO & IPM & 0.59 & 1.93 & 1.22 \\ 
  HECO & QBM & 0.60 & 5.64 & 1.22 \\ 
  PASM & IPM & 0.15 & 0.49 & 0.40 \\ 
  PASM & QBM & 0.20 & 1.59 & 0.40 \\ 
  POSE & IPM & 0.71 & 1.66 & 1.23 \\ 
  POSE & QBM & 0.76 & 3.52 & 1.23 \\ 
   \hline
\end{tabular}
\end{table}

\pagebreak{}
--->

\newpage{}

Figures
-------
```{r figure_1, dependson="plot-options", fig.cap="Time series of average percent cover over all quadrats for our four focal species: *Bouteloua gracilis* (BOGR), *Hesperostipa comata* (HECO), *Pascopyrum smithii* (PASM), and *Poa secunda* (POSE). Light grey lines show trajectories of individual quadrats. Note the different y-axis scales across panels.", fig.height=2, fig.width=8.5, eval=T}
library(ggthemes)
obs_data <- read.csv("../analysis/data_processing/speciesData/quadAllCover.csv")
#remove zeros for averaging
obs_data <- obs_data[which(obs_data$propCover>0),]
avgobs <- ddply(obs_data, .(year, Species), summarise,
                mean_cover = mean(propCover))

ggplot()+
  geom_line(data = obs_data, aes(x=(1900+year), y=propCover*100, group=quad), 
            color="grey", size=0.25)+
  geom_line(data=avgobs, aes(x=(1900+year), y=mean_cover*100))+
  geom_point(data=avgobs, aes(x=(1900+year), y=mean_cover*100),size=3)+
  ylab("Mean cover (%)")+
  xlab("Year")+
  theme_few()+
  facet_wrap("Species", ncol=4, nrow=1, scales = "free")+
  guides(shape=FALSE, linetype=FALSE)
```

\newpage{}

<!---
\begin{figure}[!ht]
  \centering
      \includegraphics[width=4in]{./components/micromeso_flowchart.png}
  \caption{Work flow of the data aggregation, model fitting, and population simulating.}
\end{figure}

\newpage{}


\begin{figure}[!ht]
  \centering
      \includegraphics[width=6in]{./components/lppds_suppfig.png}
  \caption{Cross validation scores (summed log pointwise predictive density) plotted against the prior variance for $\boldsymbol{\beta}_C$. The optimal score for prediction for each species-vital rate combination is shown with a vertical red line.}
\end{figure}

\newpage{}
--->
\begin{figure}[!ht]
  \centering
      \includegraphics[height=6in]{./components/forecast_accuracy_mockup.png}
  \caption{Comparison of one-step-ahead, out-of-sample forecast accuracy between the IPM and QBM models with and without the inclusion of climate covariates. Comparisons between equivalent IPM and QBM models indicate no significant difference in accuracy (\emph{P} > 0.05 for all comparisons). Including climate covariates resulted in siginificantly higher forecast accuracy for only one species, \emph{Poa secunda} (\emph{P} = 0.043). Species codes are as in Fig. 1}
\end{figure}

\newpage{}

\begin{figure}[!ht]
  \centering
      \includegraphics[height=7in]{./components/climate_posteriors_figure.png}
  \caption{Posterior distributions of climate effects ($\boldsymbol{\beta}_C$) for each species and vital rate statistical model. Because our priors were constrained via ridge-regression, we highlight climate effects whose 80\% credible intervals do not overlap zero (red for negative coefficients, blue for positive coefficients). Kernel bandwidths of posterior densities were adjusted by a factor of 4 for visual clarity. Species codes are as in Fig. 1.}
\end{figure}

\newpage{}

\begin{figure}[!ht]
  \centering
      \includegraphics[height=5in]{./components/forecast_horizon.png}
  \caption{The forecast horizons for both models with climate covariates included. Points show the average accuracy ($\rho$) across all forecasts at a given time horizon. We only examine the forecast accuracy of models with climate covariates included because in no case did including climate covariates decrease accuracy (see Fig. 2). Species codes are as in Fig. 1.}
\end{figure}


\newpage{}

<!---
\begin{figure}[!ht]
  \centering
      \includegraphics[height=6in]{./components/climate_effect_corplots.png}
  \caption{Correlations between QBM and IPM estimates of climate effects. We ignore sizeXclimate interactions since these are not directly comparable across model types. The QBM does not have multiple vital rates, so its values are repeated across panels within each species. Across top panels, 'growth' = growth regression, 'rec' = recruitment regression, 'surv' = survival regression.}
\end{figure}

\newpage{}


\begin{figure}[!ht]
  \centering
      \includegraphics[height=6in]{./components/climate_change_results.png}
  \caption{Mean (points) and 90\% quantiles (errorbars) for the proportional difference between baseline simulations (using observed climate) and the climate pertubation simulation on the x-axis. We calculated proportional difference as log(perturbed climate cover) - log(observed climate cover), where 'perturbed' and 'observed' refer to the climate time series used to drive interannual variation in the simulations. Model error and parameter uncertainty were propagated through the simulation phase.}
\end{figure}

\pagebreak{}
--->

```{r figure_3, dependson="plot-options", fig.cap="Sensitivity of equilibrium cover simulated from the IPM to each climate scenario applied to individual and combined vital rates. For example, the points associated with G show the median cover from IPM simulations where a climate perturbation is applied only to the growth regression climate covariates. These simulations use mean parameter values for clarity.", fig.width=8, fig.height=6, cache=FALSE, results='hide', eval=F}
setwd("~/Repos/MicroMesoForecast/analysis/")

####
####  Make IPM sensitivity plot for lower panels
####
setwd("../analysis/ipm/simulations/results/climate_sensitivity/")
files <- list.files()
cover_files <- files[grep("cover", files)]
spp_id <- substr(cover_files, 1, 4)
num_files <- length(cover_files)
all_sims <- data.frame(time=NA, cover=NA, species=NA, climsim=NA, vital=NA)
for(i in 1:num_files){
  tmp <- read.csv(cover_files[i])
  tmp$species <- rep(spp_id[i], nrow(tmp))
  all_sims <- rbind(all_sims, tmp)
}
all_sims <- all_sims[2:nrow(all_sims),]

# Rename vital rates with codes
vital_names <- unique(all_sims$vital)
vital_codes <- c("A", "G", "GR", "GS", "R", "S" , "SR") 
vitals <- data.frame(names=vital_names,code=vital_codes)
for(vnow in vital_names){
  ids <- which(all_sims[,"vital"]==vnow)
  idcode <- which(vitals[,"names"]==vnow)
  all_sims[ids,"vital"] <- as.character(vitals[idcode,"code"])
}

# Rep the 'all' simulation for each vital rate for plotting
all_clim_sims <- subset(all_sims, vital=="A")
species <- unique(all_sims$species)
out_controls <- data.frame(time=NA, cover=NA, species=NA, climsim=NA, vital=NA)
for(spp in species){
  tmp <- subset(all_clim_sims, species==spp)
  for(vital in vital_codes){
    tmp$vital <- vital
    out_controls <- rbind(out_controls, tmp)
  }
}
out_controls <- out_controls[2:nrow(out_controls),]

# Combine the datasets
all_noclim_sims <- subset(all_sims, vital!="all")
final <- rbind(out_controls, all_noclim_sims)

# Calculate statistics for plotting
equilibrium_cover <- ddply(final, .(species, climsim, vital), summarise,
                           eq_cover = median(cover))
mean_cover <- ddply(subset(equilibrium_cover, climsim=="all"), .(species), summarise,
                    value = mean(eq_cover))


equilibrium_cover <- subset(equilibrium_cover, vital!="A")
bothid <- which(equilibrium_cover[,"climsim"]=="ppttemp")
equilibrium_cover[bothid,"climsim"] <- "zppttemp"
# myCols2 <- c("#277BA8", "#7ABBBD", "#AED77A")
sensplot <- ggplot(equilibrium_cover, aes(x=climsim, y=eq_cover*100, 
                              shape=vital, group=vital, linetype=vital))+
  geom_hline(data=mean_cover, aes(yintercept=value*100), linetype=2, color="grey45")+
  geom_line()+
  geom_point(size=4)+
  facet_wrap("species", scales = "free", ncol=2)+
  scale_linetype_discrete(name="Vital Rate")+
  scale_shape_discrete(name="Vital Rate")+
  scale_x_discrete(labels=c("baseline", "+ppt", "+temp", "+ppt&temp"))+
  ylab("Equilibrium Cover (%)")+
  xlab("Simulation")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

covertest <- subset(equilibrium_cover, climsim=="all")
colnames(covertest)[4] <- "obs_cover"
out <- merge(subset(equilibrium_cover, climsim!="all"), covertest[,c("species","vital","obs_cover")])
out$propdiff <- with(out, log(eq_cover*100)-log(obs_cover*100))

# meanparamplot <- grid.arrange(meanplot, sensplot, ncol=1, nrow=2)
# print(meanparamplot)
print(sensplot)

setwd("~/Repos/MicroMesoForecast/manuscript")
```

```{r figure_4, dependson="plot-options", fig.cap="Effect of quadrat sample size on the precision (standard deviation) of main climate effect estimates in the QBM. Increasing the number of quadrats results in diminishing returns in terms of parameter certainty. Light dashed lines show individual climate effects at five quadrat sample sizes. Thick dark lines are inverse gaussian fits showing the mean effect of increasing quadrat sample size on parameter precision.", fig.width=3, fig.height=7.5, cache=FALSE, results='hide', eval=F}
library(mgcv)

setwd("../analysis/quadBM/vitalRateRegressions/exclude_quad_test")

####
####  Read in model fits and summarize results
####
source("popgrowth_read_data.R")
spp <- unique(growD_all$Species)
num_quads <- numeric(length(spp))
for(i in 1:length(spp)){
  tmp <- subset(growD_all, Species==spp[i])
  num_quads[i] <- length(unique(tmp$quad))
}
num_quads <- as.data.frame(num_quads)
num_quads$species <- spp

all_files <- list.files("./results/")
all_fits <- data.frame(Parameter=NA, stddev=NA, id=NA, 
                       rmsquad=NA, rep=NA, species=NA)
for(i in 1:length(all_files)){
  tmp <- all_files[i]
  spp <- substring(tmp, 1, 4)
  qsrm1 <- unlist(strsplit(tmp, "[_]"))[2]
  qsrm <- gsub("numout", "", qsrm1)
  rep1 <- unlist(strsplit(tmp, "[_]"))[3]
  rep2 <- gsub(".RDS","",rep1)
  rep <- gsub("rep", "", rep2)
  
  long <- readRDS(paste("./results/",tmp, sep=""))
  short <- ddply(long, .(Parameter), summarise,
                 stddev = sd(value))
  climeff <- short[grep("b2", short$Parameter),]
  climeff$id <- substr(climeff$Parameter, 4, length(climeff$Parameter))
  climeff$id <- as.numeric(unlist(strsplit(climeff$id, split=']')))  
  climeff <- climeff[with(climeff, order(id)),]
  climeff$rmsquad <- qsrm
  climeff$rep <- rep
  climeff$species <- spp
  all_fits <- rbind(all_fits, climeff)
} # end file loop

all_fits <- all_fits[2:nrow(all_fits),]

####
####  Read in full fits
####
dir <- "../truncNormModel/"
files <- list.files(dir)
files <- files[grep(".RDS", files)]
all_alls <- data.frame(Parameter=NA, stddev=NA, id=NA, 
                       rmsquad=NA, rep=NA, species=NA)
for(i in 1:length(files)){
  tmp <- files[i]
  spp1 <- unlist(strsplit(tmp, "[_]"))[3]
  spp <- gsub(".RDS","",spp1)
  
  long <- readRDS(paste(dir,tmp, sep=""))
  short <- ddply(long, .(Parameter), summarise,
                 stddev = sd(value))
  climeff <- short[grep("b2", short$Parameter),]
  climeff$id <- substr(climeff$Parameter, 4, length(climeff$Parameter))
  climeff$id <- as.numeric(unlist(strsplit(climeff$id, split=']')))  
  climeff <- climeff[with(climeff, order(id)),]
  climeff$rmsquad <- 0
  climeff$rep <- 1
  climeff$species <- spp
  all_alls <- rbind(all_alls, climeff)
}
all_alls <- all_alls[2:nrow(all_alls),]

####
####  Aggregate results by species and rep
####
all_fits <- rbind(all_fits, all_alls)
agg_fits <- ddply(all_fits, .(Parameter, rmsquad, species, id), summarise,
                  avg_stddev = mean(stddev))
agg_fits2 <- agg_fits[which(agg_fits$id %in% c(1:5)),]
agg_fits2 <- merge(agg_fits2, num_quads, by="species")
agg_fits2$quadsfit <- with(agg_fits2, num_quads-as.numeric(rmsquad))


####
####  Fit model (need to do by species)
####
modBOGR <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="BOGR"),
               family=quasi(link="1/mu^2"))
modHECO <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="HECO"),
               family=quasi(link="1/mu^2"))
modPASM <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="PASM"),
               family=quasi(link="1/mu^2"))
modPOSE <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="POSE"),
               family=quasi(link="1/mu^2"))
summary(modBOGR)
summary(modHECO)
summary(modPASM)
summary(modPOSE)


####
#### Plot
####
ggplot(agg_fits2, aes(x=quadsfit, y=avg_stddev))+
  geom_line(aes(group=Parameter), alpha=0.3, linetype=2)+
  geom_point(aes(group=Parameter), alpha=0.3, size=3)+
#   stat_smooth(method="loess", size=2, color="black", se=FALSE)+
  geom_smooth(method="glm", formula=y~x, family=quasi(link="1/mu^2"),
              size=2, color="black", se=FALSE)+
  facet_wrap("species", scales = "free", ncol=1)+
  theme_bw()+
  xlab("Number of quadrats fit")+
  ylab("Standard deviation of coefficient")


```


\singlespace{}

References
----------
