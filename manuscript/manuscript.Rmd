---
layout: 12pt
header-includes:
   - \usepackage{lineno}
   - \linenumbers
   - \usepackage{setspace}
   - \doublespacing
bibliography: ~/Dropbox/Bibliography/MicroMeso.bib
csl: components/ecology.csl

## rmarkdown render options
output:
  pdf_document:
    fig_caption: true
    keep_tex: true
fontsize: 12pt
geometry: margin=1in

---

Do we need detailed demographic data to forecast the impacts of climate change on plant populations?
========================================================================================

### Andrew T. Tredennick[^corrauth] and Peter B. Adler

*Andrew T. Tredennick, Department of Wildland Resources and the Ecology Center, Utah State University, Logan, UT*

*Peter B. Adler, Department of Wildland Resources and the Ecology Center, Utah State University, Logan, UT*

[^corrauth]: Corresponding author: [atredenn@gmail.com](mailto:atredenn@gmail.com)

```{r libraris, include=FALSE}
library(ggplot2)
library(plyr)
library(gridExtra)
library(reshape2)
library(xtable)
library(ggmcmc)
```

```{r caching, include=FALSE}
library("methods")
library("knitr")
basename <- "manuscript"
opts_chunk$set(fig.path = paste("components/figure/", basename, "-", sep=""),
               cache.path = paste("components/cache/", basename, "/", sep=""))
opts_chunk$set(cache = 2)
opts_chunk$set(tidy=FALSE, warning=FALSE, message=FALSE, 
               comment = NA, verbose = TRUE, echo=FALSE)

# PDF-based figures
opts_chunk$set(dev='pdf')
```


```{r plot-options, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
               "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

opts_chunk$set(dev='pdf', dev.args=c(version="1.3"))

```

Abstract
--------
The ability of population models to skillfully forecast future states under climate change is constrained by the limited spatial and temporal extent of demographic data. This data is often limited because it is difficult and costly to collect. An alternative is to rely on aggregate, population-level data that is easier and less costly to collect. Doing so requires assuming that population-level data accurately represents the aggregate response of the individuals that actually respond to weather. We tested this assumption using population models of four Montana grassland species fit using individual and aggregated forms of the same data. We fit population models with interannual variation in vital rates explained, in part, by climate covariates and then perturbed observed climate to compare model forecasts. Population models based on individual-level demographic data outperformed the models based on aggregate-level data in terms of accuracy and precision. The two model types produced inconsistent forecasts when we perturbed climate. Thus, it seems that, at least for the species in this location, demographic data is necessary to pick up key climate drivers of vital rates like survival that are not well resolved in aggregated data. On a pessimistic note, our work shows that even with detailed demographic data, model forecasts are extremely uncertain. It is becoming clear the long time series (over two decades) are necessary to produce meaningful forecasts. 

*Keywords*: forecasting, climate change, grassland, integral projection model, population model

Introduction
------------
Population models are important tools for predicting the impacts of environmental change on species. But reconciling the scales at which population models are parameterized and the scales at which environmental changes play out remains a challenge [@Clark2010; @Freckleton2011; @Queenborough2011; @Clark2012]. The major hurdle is that most population models, at least for plant species, are built using data from small, localized plots because parameterizing traditional population models requires tracking the fates of individuals. These models are difficult to scale up from the micro to meso-scales because the fitted parameters do not fully represent the spatial variation present at scales beyond that at which the data are collected [@SÃ¦ther2007]. At the same time, most demographic data is collected over short time spans. For example, the most common study duration in the COMPADRE matrix population model database is 4 years and only a few exceed 10 years [@Salguero-Gomez2015]. The constrained spatio-temporal extent of most demographic datasets reflects the difficulty of collecting such data, but those constraints limit our ability to extrapolate population models. Thus, our ability to use population models to predict the consequences of climate change is limited when we rely on individual-level data.

Aggregate measures of individual plant performance, such as those typically collected as part of large-scale census efforts, offer an alternative to detailed demographic data for modeling populations [@Clark2004; @Freckleton2011]. Such population-level data will never match the precision of individual-level data, but it is more feasible to attain a broad coverage sample when collecting coarse-scale data. This presents a difficult trade-off: on the one hand, individual-level data leads to more reliable models; on the other hand, population-level data leads to models that will produce less precise predictions but can be applied over greater spatial and temporal extents. An open question is how well models based on population-level data compare to models based on individual-level data.

To date, relatively few studies have tried to model populations based on data other than detailed individual-level data. An important exception is an effort by @Taylor2004 to model the population growth rate of an invasive species to investigate the best strategies for invasion control. They used a "density-structured" model where the state variable is a discrete density state rather than a continuous density measure. Building on this work, @Freckleton2011 showed that density-structured models compare well to continuous models in theory, and @Queenborough2011 showed the application of such methods in a study on arable weeds. In particular, @Queenborough2011 provide empirical evidence that density-structured models are capable of reproducing population dynamics, even if some precision is lost when compared to fully continuous models. Thus, population models based on coarse, population-level data show promise for producing ecological forecasts at landscape and regional scales [@Queenborough2011]. However, none of these models included environmental covariates.

Basing population models on aggregated individual-level data in a climate change context is hampered by the fact that it is individuals that respond to climate, not populations [@Clark2012]. This fact puts us in uneasy proximity to an "ecological fallacy" where one deduces inference on the individual from statistical inference on the group [@PIANTADOSI1988]. For example, individual plants may respond positively to precipitation but a negative trend is observed at the population level due to increased competition among plants as they grow larger and consume more resources. Thus, it is important to ask the question: Can aggregated data be used to detect climate signals of the same sign and magnitude as individual-level data? If not, then building population models with climate covariates on aggregated data will lead to incorrect forecasts.

Here, we test the assumption that statistical and population models based on aggregated data can detect climate signals as wells as models based on individual-level data. We use a unique demographic dataset that tracks the fates of individual plants from four species over 14 years to build single-species population models, since those are often used tools for ecological forecasts and climate vulnerability assessments. We first fit population models with interannual variation in vital rates explained, in part, by climate covariates. We then perturb the climate covariates to test the sensitivities of species to climate change. By doing these analyses using both individual and aggregated forms of the same data we can directly compare the two types of models. 

In general, we find that population models based on detailed demographic data are more accurate and precise than models based on aggregated data. Both types of models are able to detect climate signals, as evidenced by the sensitivity of simulated equilbrium plant cover under a perturbed climate scenario. But the two types of models produce inconsistent forecasts, in some cases producing completely opposing predictions. This leads us to conclude that, at least for these species at this location, detailed demographic data is necessary to detect the "right" climate signal. A worrying caveat to our work is that forecasts from both models were very uncertain. It seems that even 14 years worth of demographic data is not enough to produce meaningful forecasts when model uncertainty is explicitly considered.

Materials and Methods
---------------------
### Study site and data
Our demographic data comes from the Fort Keogh Livestock and Range Research Laboratory in eastern Montana's northern mixed prairie near Miles City, Montana, USA ($46^{\circ}$ 19' N, $105^{\circ}$ 48' W). The dataset is freely available on Ecological Archives[^link] [@Anderson2011] , and interested readers should refer to the metadata therein for a complete description. The site is about 800 m above sea level and mean annual precipitation (1878-2009) is 334 mm, with most annual precipitation falling from April through September. The site is grass dominated and, for the purposes of our study, we focus on the four most abundant graminoid species: \emph{Bouteloua gracilis} (BOGR), \emph{Hesperostipa comata} (HECO), \emph{Pascopyrum smithii} (PASM), and \emph{Poa secunda} (POSE) (Fig. 1). 

[^link]: http://esapubs.org/archive/ecol/E092/143/

From 1932 to 1945 individual plants were identified and mapped annually in 44 1-$\text{m}^2$ quadrats using a pantograph. The quadrats were distributed in six pastures, each assigned a grazing treatment of light (1.24 ha/animal unit month), moderate (0.92 ha/aum), and heavy (0.76 ha/aum) stocking rates (two pastures per treatment). In this analysis we account for potential differences among the grazing treatments, but do not focus on grazing$\times$climate interactions. The annual maps of the quadrats were digitized and the fates of individual plants tracked and extracted using a computer program. Daily climate data, which we aggregated into climate variables of interest, are available for the duration of the data collection period (1932 - 1945) from the Miles City airport, Wiley Field, 9 km from the study site.

In this paper, we model populations based on two levels of data: individual and quadrat (Fig. 2). The individual data is the "raw" data. For the quadrat level we data we simply sum individual areal cover for each quadrat by species. This is equivalent to a perfect census of quadrat percent cover, so we do not need to consider measurement error. Based on these two datasets we can compare population models built using individual level data and aggregated quadrat level data.

All R code and data necessary to reproduce our analysis is archived on GitHub as release 1.0 (http://github.com/atredennick/MicroMesoForecast/releases). That stable release will remain static as a record of this analysis, but subsequent versions may appear if we update this work.

### Stastical models of vital rates
At both levels of inference (individual and quadrat), the building blocks of our population models are vital rate regressions. For individual level data we fit models for survival, growth, and recruitment of new individuals for each species. At the quadrat level we fit a single regression model for population growth. We describe the statistical models separately since fitting the models required different approaches. All models contain five climate covariate that we chose \emph{a priori}: "water year" precipitation at \emph{t}-1 (lagppt); fall through spring precipitation at \emph{t}-1 and \emph{t}-2 (ppt1 and ppt2, respectively) and mean spring temperature at \emph{t}-1 and \emph{t}-2 (TmeanSpr1 and TmeanSpr2, respectively), where \emph{t} is the observation year. We also include interactions among same-year climate covariates (e.g., ppt1 $\times$ TmeansSpr1) and climate $\times$ size interactions.

We fit all models using a hierarchical Bayesian approach, which we describe in more detail below. However, for each vital rate statistical model we also define the likelihood model we use. For the likelihood models, \textbf{Y} is always the relevant vector of observations (e.g., whether a  genet survived [1] or not [0] from year $t$ to $t+1$). 

#### Vital rate models at the individual level
We used logistic regression to model survival probability ($S$) of genet $i$ from species $j$ in quadrat group $Q$ from time $t$ to $t+1$:

\begin{align}
\text{logit}(S_{ijQ,t}) &= \gamma^{S}_{j,t} + \phi^{S}_{jQ} + \beta^{S}_{j,t}x_{ij,t} + \omega^{S}_{j}w_{ij,t} + \theta^{S}_{jk}C_{k,t} \\
Y^{S}_{ijQ,t} &\sim \text{Bernoulli}(S_{ijQ,t})
\end{align}

where $x_{ij,t}$ is the log of genet size, $\gamma^{S}_{j,t}$ is a year-specific intercept, $\beta^{S}_{j,t}$ is the year-specific slope parameter for size, $\phi^{S}_{jQ}$ is the random effect of quadrat group location, and $\theta^{S}_{k}$ is the fixed parameter for the effect of the $k$th climate covariate at time $t$ ($C_{k,t}$). We include density-dependence by estimating the effect of crowding on the focal individual by other individuals of the same species. $\omega$ is the effect of crowding and $w_{t,Q}$ is the crowding experienced by the focal individual at time $t$ in quadrat group $Q$.

We modeled growth as Gaussian process describing genet size at time $t+1$ as a function of size at $t$ and climate covariates:

\begin{align}
x_{ijQ,t+1} &= \gamma^{G}_{j,t} + \phi^{G}_{jQ} + \beta^{G}_{j,t}x_{ij,t} + \omega^{G}_{j}w_{ij,t} + \theta^{G}_{jk}C_{k,t} \\
Y^{G}_{ijQ,t} &\sim \text{Normal}(x_{ijQ,t+1}, \sigma_{j})
\end{align}

where $x$ is log genet size and all other parameters are as described for the survival regression.

Our data allows us to track new recruits, but we cannot assign a specific parent to new genets. So, for recruitment, we work at the quadrat level and model the number of new individuals of species $j$ in quadrat $q$ recruiting at time $t+1$ as a function of quadrat "effective cover" ($A'$) in the previous year ($t$). Effective cover is a mixture of observed cover ($A$) in the focal quadrat ($q$) and the mean cover across the entire group ($\bar{A}$) of $Q$ quadrats in which $q$ is located:

\begin{equation}
A'_{jq,t} = p_{j}A_{jq,t} + (1-p_{j})\bar{A}_{jQ,t}
\end{equation}

where $p$ is a mixing fraction between 0 and 1 that is estimated within the model.

We assume the number of individuals, $Y^{R}$, recruiting at time $t+1$ follows a negative binomial distribution:

\begin{equation}
Y^{R}_{jq,t+1} \sim \text{NegBin}(\lambda_{jq,t+1},\zeta)
\end{equation}

where $\lambda$ is the mean intensity and $\zeta$ is the size parameter. We define $\lambda$ as:

\begin{equation}
\lambda_{jq,t+1} = A'_{jq,t}e^{(\gamma^{R}_{j,t} + \phi^{R}_{jQ} + \theta^{R}_{jk}C_{k,t} + \omega^{R}\sqrt{A'_{q,t}})}
\end{equation}

where $A'$ is effective cover ($\text{cm}^2$) of species $j$ in quadrat $q$ and all other terms are as in the survival and growth regressions.

#### Population model at the quadrat level
The statistical approach used to model vital rates using aggregated data depends on the type of data collected. In our case, and as is often the case with census data, we have percent cover data (which can easily be transformed to proportion data, of course). We first considered fitting three vital rate models analagous to those we fit at the individual level: one for probability of extirpation within a quadrat (analagous to survival), one for cover change within a quadrat (analagous to growth), and one for probability of colonization within a quadrat (analagous to recruitment). However, within-quadrat extirpation and colonization events were rare in our time series ($N=9$ and $N=10$, respectively across all species). Given the broad spatial distribution of the quadrats we are studying, it is safe to assume that these events are in fact rare enough to be ignored for our purposes. So we constrained our statistical modeling of vital rates at the population level to change in percent cover within quadrats. For the remaining discussion of statistical modeling we refer to proportion data, which is simply percent data divided by 100.

An obvious choice for fitting a linear model to proportion data is beta regression because the support of the beta distribution is [0,1], not including true zeros or ones. However, when we used fitted model parameters from a beta regression in a quadrat-based population model the simulated population tended toward 100% cover for all species. We therefore chose a more constrained modeling approach based on a truncated log-normal likelihood. The model for quadrat cover change ($G$) from time $t$ to $t+1$ is

\begin{align}
x_{jq,t+1} &= \gamma^{G}_{j,t} + \phi^{G}_{jQ} + \beta^{G}_{j,t}x_{jq,t} + \theta^{S}_{jk}C_{k,t} \\
Y^{G}_{jq,t+1} &\sim \text{LogNormal}(x_{jq,t+1}, \tau{j}) \text{T}[0,1]
\end{align}

where $x_{jq,t}$ is the log of species' $j$ proportional cover in quadrat $q$ at time $t$ and all other parameters are as in the individual-level growth model (Eq. 3). The log normal likelihood includes a truncation (T[0,1]) to ensure that predicted values do not exceed 100% cover. 

### Model fitting
Our Bayesian approach to fitting the vital rate models required choosing appropriate priors for unknown parameters and deciding which, if any, of those priors should be hierarchical. We decided to fit models where all terms were fit by species. Within a species, we fit yearly size effects and yearly intercepts hierarchically where year-specific coefficients were drawn from global distributions representing the mean size effect and intercept. We used flat, uninformative priors for all unknown parameters (Appendix X).

All of our analyses (model fitting and simulating) were conducted in R [@R2013]. We used the 'No-U-Turn' MCMC sampler in Stan [@stan2014]  to estimate the posterior distributions of model parameters using the package 'rstan' [@rstan2014]. We obtained posterior distributions for all model parameters from three parallel MCMC chains run for 1,000 iterations after discarding an initial 1,000 iterations. We recignize such short MCMC chains may surprise those more familiar with other MCMC samplers (i.e. JAGS or WinBUGS), but the Stan sampler is exceptionally efficient, which reduces the number of iterations needed to achieve convergence. We assessed convergence visually and made sure scale reduction factors for all parameters were less than 1.01. For the purposes of including parameter uncertainty in our population models, we saved the final 1,000 iterations from each of the three MCMC chains for all parameters to be used as randomly drawn values during population simulation. This step alleviates the need to reduce model parameters by model selection since sampling from the full parameter space in the MCMC ensures that if a parameter broadly overlaps zero, on average the effect in the population models will also be near zero.

### Population models
With the posterior distribution of the vital rate statistical models in hand, it is straightforward to simulate the population models. We used an Integral Projection Model (IPM) to model populations based on individual level data and an quadrat based version of an individually-based model (Quadrat-Based Model, QBM) to model populations based on quadrat level data. We describe each in turn.

#### Integral projection model
We use an environmentally stochastic IPM [@Rees2009] that includes the random year effects and the climate covariates from the vital rate statistical models. But note that we can, and do for some simulations, ignore the random year effects so that only the climate effects can drive interannual variation. Our IPM follows the specification of @Chu2015 where the population of species _j_ is a density function $n(u_{j},t)$ giving the density of sized-_u_ genets at time _t_. Genet size is on the natural log scale, so that $n(u_{j},t)du$ is the number of genets whose area (on the arithmetic scale) is between $e^{u_{j}}$ and $e^{u_{j}+du}$. So, the density function for any size _v_ at time $t+1$ is

\begin{equation}
n(v_{j},t+1) = \int_{L_{j}}^{U_{j}} k_{j}(v_{j},u_{j},\bar{\bold{w_{j}}}(u_{j}))n(u_{j},t)
\end{equation}

where $k_{j}(v_{j},u_{j},\bar{\bold{w_{j}}})$ is the population kernal that describes all possible transitions from size $u$ to $v$ and $\bar{\bold{w_{j}}}$ is a vector of estimates of average crowding experienced from all other species by a genet of size $u_j$ and species $j$. The integral is evaluated over all possible sizes between predefined lower (_L_) and upper (_U_) size limits that extend beyond the range of observed genet sizes.

The population kernal is defined as the joint contributions of survival (_S_), growth (_G_), and recruitment (_R_):

\begin{equation}
k_{j}(v_{j},u_{j},\bar{\bold{w_{j}}}) = S_j(u_j, \bar{\bold{w_{j}}}(u_{j}))G_j(v_{j},u_{j},\bar{\bold{w_{j}}}(u_{j})) + R_j(v_{j},u_{j},\bar{\bold{w_{j}}}),
\end{equation}

which, said plainly, means we are calculating growth (_G_) for individuals that survive (_S_) from time _t_ to _t+1_ and adding in newly recruited (_R_) individuals of an average sized one-year-old genet for the focal species. Our stastical model for recruitment (_R_, described above) returns the number of new recruit produced per quadrat. Following previous work [@Adler2012; @Chu2015], we assume that fecundity increases linearly with size ($R_j(v_{j},u_{j},\bar{\bold{w_{j}}}) = e^{u_j}R_j(v_{j},\bar{\bold{w_{j}}})$) to incorporate the recruitment function in the spatially-implicit IPM.

We used random draws from the final 1,000 iterations from each of three MCMC chains to introduce stochasticity into our population models. At each time step, we randomly selected climate covariates from one of the 14 observed years. Then, we drew the full parameter set (climate effects and density-dependence fixed effects) from a randomly selected MCMC iteration. Using this approach, rather than simply using coefficient point estimates, ensures that relatively unimportant climate covariates (those that broadly overlap 0) have little effect on the simulation results. Since our focus was on the contribution of climate covariates to population states, we set the random year effects and the random group effects to zero.

#### Quad-based model
Our quad-based model (QBM) perfectly mirrors its statistical description (Eq. 8-9). We use the same approach for drawing parameter values as described for the IPM.

### Model validation
To test each model's ability to forecast the population state we made out of sample predictions using leave-one-year-out cross validation. For both levels of modeling, we fit the vital rate models using observations from all years except one, and then used those fitted parameters in the population models to perform a one-step-ahead forecast for the year whose observations were withheld from model fitting. Within each observation year, several quadrats are sampled. So we made predictions for each observed quadrat in the focal year initialized with cover the previous year. Since we were making quadrat specific predictions we incorporated the group effect on the intercept for both models. We repeated this procedure for all 13 observation years, making 100 one-step-ahead forecasts for each quadrat-year combination with parameter uncertainty included via randomdrawd from the MCMC chain as described above. Random year effects were set to zero since year effects cannot be assigned to unobserved years. 

This model validation allowed us to compare accuracy and precision of the two modeling approaches (individual-level versus population-level). We first calculated the median predicted cover across the 100 simulations for each quadrat-year and then calculated the absolute error as the difference between the observed cover for a given quadrat-year and the median prediction. To arrive at mean absolute error (MAE), we then averaged the absolute error within each species across the quadrat-year specific errors. We use MAE as our measure of accuracy. To measure precision we calculated the distance between the upper and lower 90th quantiles of the 100 predictions and averaged this value over quadrat-years for each species.

### Testing sensitivity to climate covariates
Our main goal in this paper is to see if models based on aggregate level data are as sensitive to climate as models based on individual level data. So, with our fitted and validated models in hand, we ran simulations for each model type (IPM and QBM) under four climate perturbation scenarios: (1) observed climate, (2) precipitation increased by 1%, (3) temperature increased by 1%, and (4) precipitation and temperature increased by 1%. We ran the simulations for 2,500 time steps, enough to estimate equilibrium cover after discarding an initial 500 time steps as burn-in. Each simulation was run under two parameter scenarios: (1) using mean parameter estimates and (2) using randomly drawn parameters from the MCMC chain. We use (1) to detect the overall sensitivity of equilibrium cover to climate, and we use (2) to show the impact of model uncertainty on forecast precision.

As an effort to identify potential discrepencies between IPM and QBM forecasts, we also ran simulations designed to quantify the sensitivities of individual and combined vital rates to climate for the IPM. Specifically, we ran simulations for the above climate scenarios, but applied the perturbed climate covariates to survival, growth, and recruitment vital rates individually and in pairwise combinations. This allows us to isolate the vital rate(s) most sensitive to climate. For this analysis, we used mean parameter estimates to reduce the sources of uncertainty in the sensitivity estimates.

Results
-------
### Comparison of forecast models
The IPM had significantly lower overall error (MAE, mean absolute error) for three species (*B. gracilis*, *H. comata*, *P. smithii*; Table 1). In no case did the QBM significantly outperform the IPM (Table 1). The IPM was consistently more precise than the QBM, with lower distances between the 90% quantiles across all species (Table 1). In general the IPM outperformed the QBM because it had (1) lower MAE for three of the four species, (2) statistically similar MAE for the one other species, and (3) considerably more precise forecasts for all species.

### Sensitivity of models to climate
```{r get_results, echo=FALSE, eval=TRUE}
setwd("~/Repos/MicroMesoForecast/analysis/")

####
##  Mean parameter runs
####
meanparam_ipm <- data.frame(cover=NA, species=NA, 
                             climsim=NA, model=NA)
##  IPM 
path <- "./ipm/simulations/results/climchange_meanparams/"
ipmfiles_mean <- list.files(path)
ipmfiles_mean <- ipmfiles_mean[grep("cover", ipmfiles_mean)]
for(file in ipmfiles_mean){
  tmp <- read.csv(paste(path,file,sep=""))
  tmp$model <- "IPM"
  meanparam_ipm <- rbind(meanparam_ipm, tmp[,c("cover", "species", "climsim", "model")])
}
meanparam_ipm <- meanparam_ipm[2:nrow(meanparam_ipm),]

newd <- data.frame(cover=NA, species=NA, 
                   climsim=NA, model=NA, obscover=NA)
for(dospp in unique(meanparam_ipm$species)){
  tmp <- subset(meanparam_ipm, species==dospp)
  obscover <- subset(tmp, climsim=="obs")["cover"]
  tmp2 <- subset(tmp, climsim!="obs")
  tmp2$obscover <- rep(obscover$cover, times = length(unique(tmp2$climsim)))
  newd <- rbind(newd, tmp2)
}
ipm_meansims <- newd[2:nrow(newd),]
ipm_meansims$propdiff <- with(ipm_meansims, log(cover*100)-log(obscover*100))

##  QBM
meanparam_qbm <- data.frame(cover=NA, species=NA, 
                             climsim=NA, model=NA)
path <- "./quadBM/simulations/results/climatechange_meanparams/"
qbmfiles_mean <- list.files(path)
for(file in qbmfiles_mean){
  tmp <- readRDS(paste(path,file,sep=""))
  tmp$model <- "QBM"
  meanparam_qbm <- rbind(meanparam_qbm, tmp[,c("cover", "species", "climsim", "model")])
}
meanparam_qbm <- meanparam_qbm[2:nrow(meanparam_qbm),]

newd <- data.frame(cover=NA, species=NA, 
                   climsim=NA, model=NA, obscover=NA)
for(dospp in unique(meanparam_qbm$species)){
  tmp <- subset(meanparam_qbm, species==dospp)
  obscover <- subset(tmp, climsim=="obs")["cover"]
  tmp2 <- subset(tmp, climsim!="obs")
  tmp2$obscover <- rep(obscover$cover, times = length(unique(tmp2$climsim)))
  newd <- rbind(newd, tmp2)
}
qbm_meansims <- newd[2:nrow(newd),]
qbm_meansims$propdiff <- with(qbm_meansims, log(cover*100)-log(obscover*100))

##  Merge IPM and QBM mean parameter results
bothmodel_outs <- rbind(ipm_meansims, qbm_meansims)
meanparam_agg <- ddply(bothmodel_outs, .(species, climsim, model), summarise,
                       meandiff = mean(propdiff),
                       hidiff = quantile(propdiff, probs = 0.95),
                       lodiff = quantile(propdiff, probs = 0.05))
setwd("~/Repos/MicroMesoForecast/manuscript")
```

Equilibrium cover from both models was sensitive to climate (Fig. 3a-d). The IPM projected percent changes in equilibrium cover from `r round(min(subset(meanparam_agg, species=="BOGR" & model=="IPM")["meandiff"])*100)` - `r round(max(subset(meanparam_agg, species=="BOGR" & model=="IPM")["meandiff"])*100)`% for *B. gracilis*, `r round(min(subset(meanparam_agg, species=="HECO" & model=="IPM")["meandiff"])*100)` - `r round(max(subset(meanparam_agg, species=="HECO" & model=="IPM")["meandiff"])*100)`% for *H. comata*, `r round(min(subset(meanparam_agg, species=="PASM" & model=="IPM")["meandiff"])*100)` - `r round(max(subset(meanparam_agg, species=="PASM" & model=="IPM")["meandiff"])*100)`% for *P. smithii*, and `r round(min(subset(meanparam_agg, species=="POSE" & model=="IPM")["meandiff"])*100)` - `r round(max(subset(meanparam_agg, species=="POSE" & model=="IPM")["meandiff"])*100)`% for *P. secunda*. The QBM projected opposite and greater percent changes in equilibrium cover for *B. gracilis* (`r round(min(subset(meanparam_agg, species=="BOGR" & model=="QBM")["meandiff"])*100)` - `r round(max(subset(meanparam_agg, species=="BOGR" & model=="QBM")["meandiff"])*100)`%) and *H. comata* (`r round(min(subset(meanparam_agg, species=="HECO" & model=="QBM")["meandiff"])*100)` - `r round(max(subset(meanparam_agg, species=="HECO" & model=="QBM")["meandiff"])*100)`%; Fig. 3a-b). For *P. smithii*, the QBM projected opposite changes in equilibrium cover than the IPM, but of similar magnitude (`r round(min(subset(meanparam_agg, species=="PASM" & model=="QBM")["meandiff"])*100)` - `r round(max(subset(meanparam_agg, species=="PASM" & model=="QBM")["meandiff"])*100)`%; Fig. 3c). *P. secunda* was the only species that the IPM and QBM made projections of the same sign and somewhat similar magnitude (Fig. 3d). 

The response of a population to climate change is a result of the aggregate effects of climate on individual vital rates. Since the IPM approach relies on vital rate regressions, we were able to quantify the sensitivity of each vital rate in isolation and in pairwise combinations. Species showed similar trends (Fig. 3e-h). Growth was the most sensitive vital rate for all species, showing a negative response to increased precipitation, and stronger positive response to increased temperature, and a mostly positive response when both climate factors are increased (Fig. 3e-h). *B. gracilis* survival rates were sensitive to temperature, resulting in an increase in plant cover under increased temperature (Fig. 3e). In isolation, recruitment and survival were insensitive to climate factors for *H. comata* (Fig. 3f). Survival and recruitment of *P. smithii* were both sensitive, negatively, to temperature and precipitation (Fig. 3g). *P. secunda* equilibrium cover was sensitive to the climate effects on survival and recruitment, showing a negative effect on both vital rates for increased precipition, but a strong positive effect on survival with increased temperature (Fig. 3h). The climate impact of recruitment on equilibrium cover was negative for precipitation and temperature increases (Fig. 3h).

Forecasts based on 1% climate changes were extremely uncertain when we considered model error and parameter uncertainty (Fig. 4). As expected based on model validation (Table 1), QBM projections were more uncertain than IPM projections for all species except *P. smithiii* (Fig. 4).

Discussion
----------
Perhaps the greatest challenge for ecology in the 21st century is to forecast the impacts of environmental change [@Clark2001; @Petchey2015]. To do so requires sophisticated modeling approaches that fully account for uncertainty and variability in the ecological process and associated parameters [@Luo2011a]. This requires large amounts of data collected over large spatio-temporal extents. State-of-the-science modeling techniques cannot overcome data limitations. Such is the case for many population models.

As a potential remedy to the "data dearth" problem, @Queenborough2011 and @Freckleton2011, building on work by @Taylor2004, advocate a "density-structured" modeling approach. Such models do not require individual level demographic data and can adequately describe population dynamics [@Queenborough2011]. The results from density-structured models are not as precise as those from traditional population models, but the loss in precision is traded off with a gain in data. The study by @Queenborough2011 included data from 500 fields (4 hectares each) in 49 farms, all collected by two people in 6 weeks. This is far more data from a far greater spatial extent than possible if measuring individual plant demography (in a world of limited time and money, at least). The appeal of density-structured approaches is clear. 

However, at their core, density-structured models rely on individual level data aggregated to a population level metric (e.g., density classes or percent cover). This creates a potential problem if such models are to be used in a climate change context because inidividuals respond to climate, not populations [@Clark2012]. Are models based on population level metrics as sensitive to climate as models based on individual level metrics? Do these two types of models produce consistent forecasts? Do we need detailed demographic data to forecast the impacts of climate change? These are the questions we sought to answer here.

### The IPM and QBM produced inconsistent forecasts
Using individual and aggregated forms of the same dataset, we were able to directly compare a traditional demographic modeling approach to a population model based on aggregated data. Our quad-based model (QBM) is based on percent cover data and so is in the spirit of density-structured models. In terms of each model's forecasting ability, the IPM outperformed the QBM (Table 1). This is unsurprising since we expected to lose some precision at the aggregated level. However, the underwhelming performance of the QBM could call into the question forecasts that differ from the IPM.

Indeed, when we perturbed climate factors the QBM made forecasts completely contradictory to those of the IPM for three of our four study species (Fig. 3a-d). In a perfect world, the QBM would have made forecasts of at least the same direction as the IPM. If that had been the case we could conclude that aggregate level models could prove useful for forecasting climate change impacts on populations. Unfortunately, this was not the case. 

Given the superior ability of the IPM to predict out of sample observations (Table 1), we have no choice but to conclude it is the superior model. Following that logic, we can only assume that, at least contingent on the data in hand, the IPM is producing the correct forecasts to climate perturbations. The QBM failed to match IPM forecasts, implying that detailed demographic data may be necessary to accurately detect climate signals that are utlimately important at the population level. This result further confirms related work on the importance of individual variability on population level responses to exogenous drivers [@Clark2011; @Clark2011b; @Clark2012; @Galvan2014].

### The role of vital rate climate dependence
We can think of two reasons why the IPM outperformed the QBM. First, the quadrat level data has a much reduced sample size compared to the individual level data. In an ideal world we would have compared the IPM and QBM using data collected over the same amount of person hours, not just the same number of quadrats. Then the sample size of the quadrat level data would be much greater and carry more statistical power. To address this limitation in our work we fit the QBM statistical model (Eq. 8-9) with different numbers of quadrats to see the effect of sample size on the precision of climate effect estimates. It appears that including additional quadrats leads to rapidly diminishing returns in terms of parameter precision (Fig. 5). Thus, while sample size surely plays some role, we do not think it is the main driver of the difference between the IPM and QBM.

The second reason the IPM could have outperformed the QBM is that the population level model is in fact missing important climate effects that act on individual vital rates, rather than population growth. Our intuition was that species with strong climate-dependence on vital rates not well resolved at the aggregate level would result in different forecasts from the two models. For example, survival is very size dependent: smaller individuals have a higher probability of death [@Chu2014]. At the same time, a single small individual contributes relatively little to percent cover estimates at the plot scale. So, if survival of individuals was positively impacted by temperature increases, for example, we would expect to detect this signal in the individual level data but not in the aggregate level data. To see if this is the case we can regress climate effects from each vital rate statistical model at the individual level against the same climate effects from the QBM statistical model (Fig. 6). 

In general, the QBM climate effects are most correlated with climate effects from the growth model at the individual level (Fig. 6). In no case does the QBM statistical model have strong correlations across all three vital rates (Fig. 6). Thus, for each species the QBM is "missing" climate signals associated with at least one vital rate. This has large impacts on predictions of long term population dynamics, as seen in our equilibrium simulations (Fig. 3a-d).

### Forecasting the future, and the future of forecasting
Our goal was not make any explicit forecast for the future state of these populations based on predicted climate change. But our results highlight the state of affairs in ecology when it comes to forecasting the impacts of climate change. The analysis we conducted here could be considered, with some exceptions of course, at the forefront of ecological forecasting in terms of the statistical approach employed (hierarchical Bayesian), the type of population model we used (stochastic IPM with parameter uncertainty), and the amount of data we had at our disposal (14 years of individual-level data). Yet, model predictions proved so uncertain that any forecast, when bounded with model and parameter uncertainty, would be at best not useful and at worst meaningless. How might we improve on this state of affairs?

First, forecasts could be improved by matching the spatial scale of predictor variables with the spatial scale of observations. One of the major limitations of the models we fit here is that the climate data are at a much larger scale than the plot and individual level observations of plant cover and size. Climate covariates only vary by year, with no spatial variability within years. Thus, even if we fit models to individual level data, we are missing the key interaction point between weather and individual plants [@Clark2011b].

Second, accurately detecting climate signals will take even longer time series. Recent theoretical work on detecting climate signals in noisy data suggests that even advanced approaches to parameter fitting like LASSO, functional linear models (splines), and random forest require 20-25 year time series (Teller et al., in review). Alternatively, as we suggest above, Teller et al. (in review) also find that matching the scale of the response and predictors improves estimate precision.

Third, ecologists as a community need to get serious about reporting uncertainty. There is a strong culture around explicitly considering model uncertainty, but parameter uncertainty is often ignored. In some cases this is because the easiest statistical methods do no make propogating parameter uncertainty easy. But even using Bayesian approaches that allow straightforward integration of model fitting and forecasting [@Hooten2014; @Hobbs2015] is not simple when using modeling approaches like integral projection models that separate the model fitting and simulation stages [@Rees2009]. However, as we have done here, it is still possible to include parameter uncertainty by drawing parameter values from MCMC iterations, taking care to draw all parameters from the same chain and iteration to account for their correlations. Only by being honest about our forecasts cen we begin to produce better ones.


Conclusions
-----------
This work is not a critique of density-structured population models. In some cases and for certain species, population models based on aggregated data may prove useful and unbiased. However, our work here is the first comparison of population models based on individual and aggregated data in a climate change context. Our results confirm theoretical arguments [@Clark2011b] and empirical evidence [@Clark2011; @Clark2012] that individual responses are critical to predicting species' responses to climate change. Thus, forecasts from aggregate level models should be viewed with caution and should never be unaccompianed by uncertainty.

Our results also offer a cautionary tale because uncertainty around forecasts was large for both model types. Which leads us to our most pessimistic conclusion: even with 14 years of detailed demographic data and sophisticated modeling techniques we failed to produce forecasts with any level of acceptable uncertainty. In our view, uncertainty of climate change related forecasts can be reduced by (1) longer time series and (2) climate covariates that match the scale of inference (e.g., plot rather than landscape level climate/weather metrics). Still, given the poor performance of the quad-based model, it seems there is no short cut to producing accurate and precise population forecasts. Do we need detailed demographic data to forecast the impacts of climate change on populations? Probably.


Acknowledgments
---------------
This work was funded by the National Science Foundation through a Postdoctoral Research Fellowship in Biology to ATT (DBI-1400370) and a CAREER award to PBA (DEB-1054040). We thank the original mappers of the permanent quadrats in Montana and the digitizers in the Adler lab, without whom this work would not have been possible. Informal conversations with Stephen Ellner, Giles Hooker, Robin Snyder, and a series of meetings among the Adler and Weecology labs at USU sharpened our thinking. Compute, storage and other resources from the Division of Research Computing in the Office of Research and Graduate Studies at Utah State University are gratefully acknowledged.

\pagebreak{}

Tables
------
```{r table_1,results='asis',message=FALSE, comment=NA, echo=FALSE}
####
##  Make a table for average residual from each model and year effects structure
####

##  IPM results
# Read in data
ipm_onestep <- readRDS("../analysis/ipm/simulations/results/one_step_validation/ipm_loyo_forecasts_combined.rds")
# Remove predictions >1 for fair comparison to [0,1] truncated quad model
resets <- which(ipm_onestep[,"cover.t1"]>1)
ipm_onestep[resets, "cover.t1"] <- 1
# Average predictions over quad-year reps
avg_ipm <- ddply(ipm_onestep, .(species, quad, t1), summarise,
                 avg_prediction = median(cover.t1),
                 observation = mean(cover.t0),
                 quant_dist = quantile(cover.t1*100, probs = 0.95) - quantile(cover.t1, probs = 0.05))
# Calculate error
avg_ipm$error <- avg_ipm$observation*100 - avg_ipm$avg_prediction*100
# Aggregate over species
ipmstats <- ddply(avg_ipm, .(species), summarise,
                  mae = mean(abs(error)),
                  mean_cover = mean(observation*100),
                  quant_dist = mean(quant_dist))
ipmstats$model <- "IPM"


##  QBM results
# Read in data
qbm_onestep <- readRDS("../analysis/quadBM/simulations/results/one_step_validation/qbm_one-step_forecasts_combined.rds")
# Average predictions over quad-year reps
avg_qbm <- ddply(qbm_onestep, .(species, quad, year), summarise,
                 avg_prediction = median(cover.t1),
                 observation = mean(cover.t0),
                 quant_dist = quantile(cover.t1*100, probs = 0.95) - quantile(cover.t1, probs = 0.05))
# Calculate error
avg_qbm$error <- avg_qbm$observation*100 - avg_qbm$avg_prediction*100
# Aggregate over species
qbmstats <- ddply(avg_qbm, .(species), summarise,
                  mae = mean(abs(error)),
                  mean_cover = mean(observation*100),
                  quant_dist = mean(quant_dist))
qbmstats$model <- "QBM"



mae_list <- list()
mae_pvals <- list()
species <- unique(qbmstats$species)
for(spp in species){
  tmp1 <- subset(avg_ipm, species==spp)
  tmp2 <- subset(avg_qbm, species==spp)
  err1 <- as.data.frame(abs(tmp1$observation - tmp1$avg_prediction))
  err2 <- as.data.frame(abs(tmp2$observation - tmp2$avg_prediction))
  colnames(err1) <- "resid"
  err1$model <- "ipm"
  colnames(err2) <- "resid"
  err2$model <- "qbm"
  errd <-  rbind(err1, err2)
  mae_ttest <- with(errd, t.test(resid~model, alternative = "less"))
  mae_list[[spp]] <- mae_ttest
  mae_pvals[[spp]] <- mae_ttest[["p.value"]]
}

mae_ps <- melt(mae_pvals)

stats_table <- rbind(ipmstats, qbmstats)
stats_table <- stats_table[ order(stats_table[,"species"]), ]
stats_table <- stats_table[,c("species", "model", "mae",
                              "quant_dist","mean_cover")]

colnames(stats_table) <- c("Species", "Model", "MAE", "90% Distance", "Mean Obs. Cover")
print.xtable(xtable(stats_table, caption = "Accuracy (mean absolute error, MAE) and precision (90\\% Distance) of out of sample predictions. Forecasts were made without random year effects; only climate covariates could explain year-to-year variation. 90\\% Distance refers to the average distance between the upper and lower 90th percentiles of the 100 predicted values for each quadrat-year combination."),type="latex", comment=FALSE,
             include.rownames=FALSE, caption.placement="top")
```
*NOTES*: The IPM MAE is significantly lower at $\alpha=0.05$ for *B. gracilis* (*P* = `r mae_ps[1,"value"]`), *H. comata* (*P* = `r mae_ps[2,"value"]`), and *P. smithii* (*P* = `r mae_ps[3,"value"]`). MAEs are statisticially similar between models for *P. secunda* (*P* = `r mae_ps[4,"value"]`). *P* values are highly sensitive to sample size, so not entirely appropriate in simulation exercises where we control the samples size. But, for our purposes they serve as relatively unbiased comparison metrics.

\pagebreak{}
```{r table_2,results='asis',message=FALSE, comment=NA, echo=FALSE}
# qbm_diffs <- readRDS("../montana/quadBM/simulations/results/qbm_climatesims_logdiffs.RDS")
# qbm_diffs$type <- rep("QBM", nrow(qbm_diffs))
# ipm_diffs <- readRDS("../montana/ipm/simulations/results/ipm_climatesims_logdiffs.RDS")
# ipm_diffs$type <- rep("IPM", nrow(ipm_diffs))
# 
# diff_df <- rbind(qbm_diffs, ipm_diffs)
# med_cover_perc <- as.data.frame(diff_df$med_cover*100)
# med_cover_perc$model <- diff_df$type 
# med_cover_perc$sim <- diff_df$variable
# med_cover_perc$species <- diff_df$species
# colnames(med_cover_perc)[1] <- "cover"
# medcast <- dcast(med_cover_perc, species+sim~model, value.var = "cover")
# colnames(medcast) <- c("Species", "Simulation", "IPM Change (%)", "QBM Change (%)")
# simnames <- c("ppt", "temp", "ppt+temp")
# medcast$Simulation <- rep(simnames, 4)
# print.xtable(xtable(medcast, caption = "Percent change from equilibrium (temporal median of simulated plant cover) at observed climate relative to a 1\\% climate change as forecast by each model type."),type="latex", comment=FALSE,
#              include.rownames=FALSE, caption.placement="top")
```

\pagebreak{}

Figures
-------
```{r figure_1, dependson="plot-options", fig.cap="Time series of average percent cover over all quadrats for our four focal species: *Bouteloua gracilis* (BOGR), *Hesperostipa comata* (HECO), *Pascopyrum smithii* (PASM), and *Poa secunda* (POSE). Light grey lines show trajectories of individual quadrats. Note the different y-axis scales across panels.", fig.height=3, fig.width=8.5}
obs_data <- read.csv("../analysis/speciesData/quadAllCover.csv")
#remove zeros for averaging
obs_data <- obs_data[which(obs_data$propCover>0),]
avgobs <- ddply(obs_data, .(year, Species), summarise,
                mean_cover = mean(propCover))

ggplot()+
  geom_line(data = obs_data, aes(x=(1900+year), y=propCover*100, group=quad), 
            color="grey", size=0.25)+
  geom_line(data=avgobs, aes(x=(1900+year), y=mean_cover*100))+
  geom_point(data=avgobs, aes(x=(1900+year), y=mean_cover*100),size=3)+
  ylab("Mean cover (%)")+
  xlab("Year")+
  theme_bw()+
  facet_wrap("Species", ncol=4, nrow=1, scales = "free")+
  guides(shape=FALSE, linetype=FALSE)
```

```{r figure_2,dependson="plot-options", fig.cap="Work flow of the data aggregation, model fitting, and population simulating.", fig.height=6}
library(png)
library(grid)
img <- readPNG("components/figure/micromeso_flowchart.png")
grid.raster(img)
```

```{r ipm_climeffs, cache=FALSE, results='hide', include=FALSE}
# source("../montana/ipm/vitalRateRegs/climate_effects_plots.R")
# ![Standardized regression coefficients for climate effects in the vital rate models for the IPM. Shown are the median (circles), 75% confidence intervals (thick lines), and 95% confidence intervals (thin lines). Left panels (black) are for the growth regressions; middle panels (blue) are for the survival regressions; right panels (orange) are for the recruitment regressions.](components/figure/ipm_climeffs.pdf)
```


```{r quad_climeffs, cache=FALSE, results='hide', include=FALSE}
# source("../montana/quadBM/vitalRateRegressions/truncNormModel/climate_effects_plot.R")
# ![Standardized regression coefficients for climate effects in the vital rate models for the QBM. Shown are the median (circles), 75% confidence intervals (thick lines), and 95% confidence intervals (thin lines).](components/figure/qbm_climeffs.pdf)
```


```{r figure_3, dependson="plot-options", fig.cap="Proportional change in species' mean cover caused by a 1% increase in observed precipitation (+ppt), temperature (+temp), or both (+ppt&temp) as predicted by the individual-based IPM and the aggregate-based QBM using mean parameter values. Top panels show the mean predicted proportional change in cover. Lower panels show the sensitivity of equilibrium cover simulated from the IPM to each climate scenario applied to individual and combined vital rates. For example, the points associated with G show the median cover from IPM simulations where a climate perturbation is applied only to the growth regression climate covariates. These simulations also use mean parameter values for clarity.", fig.width=8.5, fig.height=5, cache=FALSE, results='hide'}
setwd("~/Repos/MicroMesoForecast/analysis/")

####
##  Mean parameter runs
####
meanparam_ipm <- data.frame(cover=NA, species=NA, 
                             climsim=NA, model=NA)
##  IPM 
path <- "./ipm/simulations/results/climchange_meanparams/"
ipmfiles_mean <- list.files(path)
ipmfiles_mean <- ipmfiles_mean[grep("cover", ipmfiles_mean)]
for(file in ipmfiles_mean){
  tmp <- read.csv(paste(path,file,sep=""))
  tmp$model <- "IPM"
  meanparam_ipm <- rbind(meanparam_ipm, tmp[,c("cover", "species", "climsim", "model")])
}
meanparam_ipm <- meanparam_ipm[2:nrow(meanparam_ipm),]

newd <- data.frame(cover=NA, species=NA, 
                   climsim=NA, model=NA, obscover=NA)
for(dospp in unique(meanparam_ipm$species)){
  tmp <- subset(meanparam_ipm, species==dospp)
  obscover <- subset(tmp, climsim=="obs")["cover"]
  tmp2 <- subset(tmp, climsim!="obs")
  tmp2$obscover <- rep(obscover$cover, times = length(unique(tmp2$climsim)))
  newd <- rbind(newd, tmp2)
}
ipm_meansims <- newd[2:nrow(newd),]
ipm_meansims$propdiff <- with(ipm_meansims, log(cover*100)-log(obscover*100))

##  QBM
meanparam_qbm <- data.frame(cover=NA, species=NA, 
                             climsim=NA, model=NA)
path <- "./quadBM/simulations/results/climatechange_meanparams/"
qbmfiles_mean <- list.files(path)
for(file in qbmfiles_mean){
  tmp <- readRDS(paste(path,file,sep=""))
  tmp$model <- "QBM"
  meanparam_qbm <- rbind(meanparam_qbm, tmp[,c("cover", "species", "climsim", "model")])
}
meanparam_qbm <- meanparam_qbm[2:nrow(meanparam_qbm),]

newd <- data.frame(cover=NA, species=NA, 
                   climsim=NA, model=NA, obscover=NA)
for(dospp in unique(meanparam_qbm$species)){
  tmp <- subset(meanparam_qbm, species==dospp)
  obscover <- subset(tmp, climsim=="obs")["cover"]
  tmp2 <- subset(tmp, climsim!="obs")
  tmp2$obscover <- rep(obscover$cover, times = length(unique(tmp2$climsim)))
  newd <- rbind(newd, tmp2)
}
qbm_meansims <- newd[2:nrow(newd),]
qbm_meansims$propdiff <- with(qbm_meansims, log(cover*100)-log(obscover*100))

##  Merge IPM and QBM mean parameter results
bothmodel_outs <- rbind(ipm_meansims, qbm_meansims)
meanparam_agg <- ddply(bothmodel_outs, .(species, climsim, model), summarise,
                       meandiff = mean(propdiff),
                       hidiff = quantile(propdiff, probs = 0.95),
                       lodiff = quantile(propdiff, probs = 0.05))
dgd = position_dodge(width = 0.9)
meanplot <- ggplot(meanparam_agg)+
  geom_bar(aes(x=climsim, y=meandiff, fill=model),
             position=dgd, stat="identity")+
  theme_bw()+
  scale_fill_manual(values=c("black", "grey45"), name="Model")+
  facet_wrap("species", scales="free", nrow=1)+
  scale_x_discrete(labels=c("+ppt", "+temp", "+ppt&temp"))+
  ylab("Mean proportional difference")+
  xlab("Climate simulation")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

####
####  Make IPM sensitivity plot for lower panels
####
setwd("../analysis/ipm/simulations/results/climate_sensitivity/")
files <- list.files()
cover_files <- files[grep("cover", files)]
spp_id <- substr(cover_files, 1, 4)
num_files <- length(cover_files)
all_sims <- data.frame(time=NA, cover=NA, species=NA, climsim=NA, vital=NA)
for(i in 1:num_files){
  tmp <- read.csv(cover_files[i])
  tmp$species <- rep(spp_id[i], nrow(tmp))
  all_sims <- rbind(all_sims, tmp)
}
all_sims <- all_sims[2:nrow(all_sims),]

# Rename vital rates with codes
vital_names <- unique(all_sims$vital)
vital_codes <- c("A", "G", "GR", "GS", "R", "S" , "SR") 
vitals <- data.frame(names=vital_names,code=vital_codes)
for(vnow in vital_names){
  ids <- which(all_sims[,"vital"]==vnow)
  idcode <- which(vitals[,"names"]==vnow)
  all_sims[ids,"vital"] <- as.character(vitals[idcode,"code"])
}

# Rep the 'all' simulation for each vital rate for plotting
all_clim_sims <- subset(all_sims, vital=="A")
species <- unique(all_sims$species)
out_controls <- data.frame(time=NA, cover=NA, species=NA, climsim=NA, vital=NA)
for(spp in species){
  tmp <- subset(all_clim_sims, species==spp)
  for(vital in vital_codes){
    tmp$vital <- vital
    out_controls <- rbind(out_controls, tmp)
  }
}
out_controls <- out_controls[2:nrow(out_controls),]

# Combine the datasets
all_noclim_sims <- subset(all_sims, vital!="all")
final <- rbind(out_controls, all_noclim_sims)

# Calculate statistics for plotting
equilibrium_cover <- ddply(final, .(species, climsim, vital), summarise,
                           eq_cover = median(cover))
mean_cover <- ddply(subset(equilibrium_cover, climsim=="all"), .(species), summarise,
                    value = mean(eq_cover))


equilibrium_cover <- subset(equilibrium_cover, vital!="A")
bothid <- which(equilibrium_cover[,"climsim"]=="ppttemp")
equilibrium_cover[bothid,"climsim"] <- "zppttemp"
# myCols2 <- c("#277BA8", "#7ABBBD", "#AED77A")
sensplot <- ggplot(equilibrium_cover, aes(x=climsim, y=eq_cover*100, 
                              shape=vital, group=vital, linetype=vital))+
  geom_hline(data=mean_cover, aes(yintercept=value*100), linetype=2, color="grey45")+
  geom_line()+
  geom_point(size=4)+
  facet_wrap("species", scales = "free", nrow=1)+
  scale_linetype_discrete(name="Vital Rate")+
  scale_shape_discrete(name="Vital Rate")+
  scale_x_discrete(labels=c("baseline", "+ppt", "+temp", "+ppt&temp"))+
  ylab("Equilibrium Cover (%)")+
  xlab("Simulation")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

covertest <- subset(equilibrium_cover, climsim=="all")
colnames(covertest)[4] <- "obs_cover"
out <- merge(subset(equilibrium_cover, climsim!="all"), covertest[,c("species","vital","obs_cover")])
out$propdiff <- with(out, log(eq_cover*100)-log(obs_cover*100))

meanparamplot <- grid.arrange(meanplot, sensplot, ncol=1, nrow=2)
print(meanparamplot)

setwd("~/Repos/MicroMesoForecast/manuscript")
```


```{r figure_4, dependson="plot-options", fig.cap="Equilibrium cover and 90% quantiles around the mean prediction when model error and parameter uncertainty are propogated through the simulation phase. Climate simulations are as in Figure 3.", fig.width=4.5, fig.height=7, cache=FALSE, results='hide'}
####
##  Vary parameter runs
####
setwd("~/Repos/MicroMesoForecast/analysis/")
meanparam_ipm <- data.frame(cover=NA, species=NA, 
                             climsim=NA, model=NA)
##  IPM 
path <- "./ipm/simulations/results/climchange_varyparams/"
ipmfiles_mean <- list.files(path)
ipmfiles_mean <- ipmfiles_mean[grep("cover", ipmfiles_mean)]
for(file in ipmfiles_mean){
  tmp <- read.csv(paste(path,file,sep=""))
  tmp$model <- "IPM"
  meanparam_ipm <- rbind(meanparam_ipm, tmp[,c("cover", "species", "climsim", "model")])
}
meanparam_ipm <- meanparam_ipm[2:nrow(meanparam_ipm),]

newd <- data.frame(cover=NA, species=NA, 
                   climsim=NA, model=NA, obscover=NA)
for(dospp in unique(meanparam_ipm$species)){
  tmp <- subset(meanparam_ipm, species==dospp)
  obscover <- subset(tmp, climsim=="obs")["cover"]
  tmp2 <- subset(tmp, climsim!="obs")
  tmp2$obscover <- rep(obscover$cover, times = length(unique(tmp2$climsim)))
  newd <- rbind(newd, tmp2)
}
ipm_meansims <- newd[2:nrow(newd),]
ipm_meansims$propdiff <- with(ipm_meansims, log(cover*100)-log(obscover*100))
# ggplot(subset(ipm_meansims, species=="PASM"))+
#   geom_histogram(aes(x=cover))+
#   facet_wrap("climsim", scales = "free")+
#   scale_x_continuous(limits=c(0,0.05))
##  QBM
meanparam_qbm <- data.frame(cover=NA, species=NA, 
                             climsim=NA, model=NA)
path <- "./quadBM/simulations/results/climatechange_varyparams/"
qbmfiles_mean <- list.files(path)
for(file in qbmfiles_mean){
  tmp <- readRDS(paste(path,file,sep=""))
  tmp$model <- "QBM"
  meanparam_qbm <- rbind(meanparam_qbm, tmp[,c("cover", "species", "climsim", "model")])
}
meanparam_qbm <- meanparam_qbm[2:nrow(meanparam_qbm),]

newd <- data.frame(cover=NA, species=NA, 
                   climsim=NA, model=NA, obscover=NA)
for(dospp in unique(meanparam_qbm$species)){
  tmp <- subset(meanparam_qbm, species==dospp)
  obscover <- subset(tmp, climsim=="obs")["cover"]
  tmp2 <- subset(tmp, climsim!="obs")
  tmp2$obscover <- rep(obscover$cover, times = length(unique(tmp2$climsim)))
  newd <- rbind(newd, tmp2)
}
qbm_meansims <- newd[2:nrow(newd),]
qbm_meansims$propdiff <- with(qbm_meansims, log(cover*100)-log(obscover*100))

##  Merge IPM and QBM mean parameter results
bothmodel_outs <- rbind(ipm_meansims, qbm_meansims)


meanparam_agg <- ddply(bothmodel_outs, .(species, climsim, model), summarise,
                       meandiff = mean(propdiff),
                       hidiff = quantile(propdiff, probs = 0.95),
                       lodiff = quantile(propdiff, probs = 0.05))
dgd = position_dodge(width = 0.6)
ggplot(meanparam_agg)+
  geom_errorbar(aes(x=climsim, ymax=hidiff, ymin=lodiff, group=model, linetype=model),
                position=dgd, width=0.25)+
  geom_point(aes(x=climsim, y=meandiff, group=model, shape=model),
                position=dgd, width=0.25)+
  theme_bw()+
  scale_linetype_discrete(name="Model")+
  scale_shape_discrete(name="Model")+
  facet_wrap("species", ncol=1, scales="free")+
  scale_x_discrete(labels=c("+ppt", "+temp", "+ppt&temp"))+
  ylab("Proportional difference")+
  xlab("Climate simulation")
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
setwd("~/Repos/MicroMesoForecast/manuscript/")
```

```{r figure_5, dependson="plot-options", fig.cap="Effect of quadrat sample size on the precision (standard deviation) of main climate effect estimates in the QBM. Increasing the number of quadrats results in diminishing returns in terms of parameter certainty. Light dashed lines show individual climate effects at five quadrat sample sizes. Thick dark lines are inverse gaussian fits showing the mean effect of increasing quadrat sample size on parameter precision.", fig.width=3, fig.height=7.5, cache=FALSE, results='hide'}
library(mgcv)

setwd("../analysis/quadBM/vitalRateRegressions/exclude_quad_test")

####
####  Read in model fits and summarize results
####
source("popgrowth_read_data.R")
spp <- unique(growD_all$Species)
num_quads <- numeric(length(spp))
for(i in 1:length(spp)){
  tmp <- subset(growD_all, Species==spp[i])
  num_quads[i] <- length(unique(tmp$quad))
}
num_quads <- as.data.frame(num_quads)
num_quads$species <- spp

all_files <- list.files("./results/")
all_fits <- data.frame(Parameter=NA, stddev=NA, id=NA, 
                       rmsquad=NA, rep=NA, species=NA)
for(i in 1:length(all_files)){
  tmp <- all_files[i]
  spp <- substring(tmp, 1, 4)
  qsrm1 <- unlist(strsplit(tmp, "[_]"))[2]
  qsrm <- gsub("numout", "", qsrm1)
  rep1 <- unlist(strsplit(tmp, "[_]"))[3]
  rep2 <- gsub(".RDS","",rep1)
  rep <- gsub("rep", "", rep2)
  
  long <- readRDS(paste("./results/",tmp, sep=""))
  short <- ddply(long, .(Parameter), summarise,
                 stddev = sd(value))
  climeff <- short[grep("b2", short$Parameter),]
  climeff$id <- substr(climeff$Parameter, 4, length(climeff$Parameter))
  climeff$id <- as.numeric(unlist(strsplit(climeff$id, split=']')))  
  climeff <- climeff[with(climeff, order(id)),]
  climeff$rmsquad <- qsrm
  climeff$rep <- rep
  climeff$species <- spp
  all_fits <- rbind(all_fits, climeff)
} # end file loop

all_fits <- all_fits[2:nrow(all_fits),]

####
####  Read in full fits
####
dir <- "../truncNormModel/"
files <- list.files(dir)
files <- files[grep(".RDS", files)]
all_alls <- data.frame(Parameter=NA, stddev=NA, id=NA, 
                       rmsquad=NA, rep=NA, species=NA)
for(i in 1:length(files)){
  tmp <- files[i]
  spp1 <- unlist(strsplit(tmp, "[_]"))[3]
  spp <- gsub(".RDS","",spp1)
  
  long <- readRDS(paste(dir,tmp, sep=""))
  short <- ddply(long, .(Parameter), summarise,
                 stddev = sd(value))
  climeff <- short[grep("b2", short$Parameter),]
  climeff$id <- substr(climeff$Parameter, 4, length(climeff$Parameter))
  climeff$id <- as.numeric(unlist(strsplit(climeff$id, split=']')))  
  climeff <- climeff[with(climeff, order(id)),]
  climeff$rmsquad <- 0
  climeff$rep <- 1
  climeff$species <- spp
  all_alls <- rbind(all_alls, climeff)
}
all_alls <- all_alls[2:nrow(all_alls),]

####
####  Aggregate results by species and rep
####
all_fits <- rbind(all_fits, all_alls)
agg_fits <- ddply(all_fits, .(Parameter, rmsquad, species, id), summarise,
                  avg_stddev = mean(stddev))
agg_fits2 <- agg_fits[which(agg_fits$id %in% c(1:5)),]
agg_fits2 <- merge(agg_fits2, num_quads, by="species")
agg_fits2$quadsfit <- with(agg_fits2, num_quads-as.numeric(rmsquad))


####
####  Fit model (need to do by species)
####
modBOGR <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="BOGR"),
               family=quasi(link="1/mu^2"))
modHECO <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="HECO"),
               family=quasi(link="1/mu^2"))
modPASM <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="PASM"),
               family=quasi(link="1/mu^2"))
modPOSE <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="POSE"),
               family=quasi(link="1/mu^2"))
summary(modBOGR)
summary(modHECO)
summary(modPASM)
summary(modPOSE)


####
#### Plot
####
ggplot(agg_fits2, aes(x=quadsfit, y=avg_stddev))+
  geom_line(aes(group=Parameter), alpha=0.3, linetype=2)+
  geom_point(aes(group=Parameter), alpha=0.3, size=3)+
#   stat_smooth(method="loess", size=2, color="black", se=FALSE)+
  geom_smooth(method="glm", formula=y~x, family=quasi(link="1/mu^2"),
              size=2, color="black", se=FALSE)+
  facet_wrap("species", scales = "free", ncol=1)+
  theme_bw()+
  xlab("Number of quadrats fit")+
  ylab("Standard deviation of coefficient")


```

```{r figure_6, dependson="plot-options", fig.cap="Correlations between QBM and IPM estimates of climate effects. We ignore sizeXclimate interactions since these are not directly comparable across model types. The QBM does not have multiple vital rates, so its values are repeated across panels within each species.", fig.width=6, fig.height=6, cache=FALSE, results='hide'}
##  Figure script to look at correlations between IPM and QBM
##    climate effect estimates.

library(ggmcmc)
library(gridExtra)
library(ggplot2)

allfiles <- list.files("../analysis/speciesData/")
removals <- grep("csv", allfiles)
species_list <- allfiles[-removals]

clim_covs <- c("pptLag", "ppt1", "ppt2", "TmeanSpr1", "TmeanSpr2",
               "ppt1xTmeanSpr1", "ppt2xTmeanSpr2",
               "sizeXpptLag", "sizeXppt1", "sizeXppt2",
               "sizeXTmeanSpr1", "sizeXTmeanSpr2")
clim_mains <- c("pptLag", "ppt1", "ppt2", "TmeanSpr1", "TmeanSpr2",
                "ppt1xTmeanSpr1", "ppt2xTmeanSpr2")


####
##  Get mean growth climate effects
####
growth_parms <- data.frame(species=NA, model=NA, parameter=NA, value=NA)
for(spp in species_list){
  tmp_data <- readRDS(paste("../analysis/ipm/vitalRateRegs/growth/growth_stanmcmc_", spp, ".RDS", sep=""))
  tmp_clim <- tmp_data[grep("b2", tmp_data[,"Parameter"]), ]
  tmp_clim[,"Parameter"] <- rep(clim_covs, each=3000)
  tmp_agg <- ddply(tmp_clim, .(Parameter), summarise,
                   value = median(value))
  tmp_agg2 <- tmp_agg[which(tmp_agg$Parameter %in% clim_mains), ]
  tmp_agg2$species <- spp
  tmp_agg2$model <- "ipm"
  colnames(tmp_agg2) <- tolower(colnames(tmp_agg2))
  growth_parms <- rbind(growth_parms,
                        tmp_agg2[,c("species", "model", "parameter", "value")])
}

####
##  Get mean survival climate effects
####
surv_parms <- data.frame(species=NA, model=NA, parameter=NA, value=NA)
params <- character(length = 12)
for(i in 1:12){
  params[i] <- paste("b2[",i,"]", sep="")
}
for(spp in species_list){
  tmp_data <- readRDS(paste("../analysis/ipm/vitalRateRegs/survival/survival_stanmcmc_", spp, ".RDS", sep=""))
  keeps <- which(tmp_data$Parameter %in% params)
  tmp_clim <- tmp_data[keeps, ]
  tmp_clim[,"Parameter"] <- rep(clim_covs, each=3000)
  tmp_agg <- ddply(tmp_clim, .(Parameter), summarise,
                   value = median(value))
  tmp_agg2 <- tmp_agg[which(tmp_agg$Parameter %in% clim_mains), ]
  tmp_agg2$species <- spp
  tmp_agg2$model <- "ipm"
  colnames(tmp_agg2) <- tolower(colnames(tmp_agg2))
  surv_parms <- rbind(surv_parms,
                        tmp_agg2[,c("species", "model", "parameter", "value")])
}


####
##  Get mean recruitment climate effects
####
rec_parms <- data.frame(species=NA, model=NA, parameter=NA, value=NA)
params <- character(length = 12)
for(i in 1:12){
  params[i] <- paste("b2[",i,"]", sep="")
}
for(spp in species_list){
  tmp_data <- readRDS(paste("../analysis/ipm/vitalRateRegs/recruitment/recruitment_stanmcmc_", spp, ".RDS", sep=""))
  keeps <- which(tmp_data$Parameter %in% params)
  tmp_clim <- tmp_data[keeps, ]
  tmp_clim[,"Parameter"] <- rep(clim_mains, each=3000)
  tmp_agg <- ddply(tmp_clim, .(Parameter), summarise,
                   value = median(value))
  tmp_agg2 <- tmp_agg[which(tmp_agg$Parameter %in% clim_mains), ]
  tmp_agg2$species <- spp
  tmp_agg2$model <- "ipm"
  colnames(tmp_agg2) <- tolower(colnames(tmp_agg2))
  rec_parms <- rbind(rec_parms,
                      tmp_agg2[,c("species", "model", "parameter", "value")])
}


####
##  Get QBM growth climate estimates
####
clim_covs2 <- c("pptLag", "ppt1", "ppt2", "TmeanSpr1", "TmeanSpr2",
               "ppt1xTmeanSpr1", "ppt2xTmeanSpr2",
               "coverXpptLag", "coverXppt1", "coverXppt2",
               "coverXTmeanSpr1", "coverXTmeanSpr2")

qbm_parms <- data.frame(species=NA, model=NA, parameter=NA, qbmvalue=NA)
params <- character(length = 12)
for(i in 1:12){
  params[i] <- paste("b2[",i,"]", sep="")
}
for(spp in species_list){
  tmp_data <- readRDS(paste("../analysis/quadBM/vitalRateRegressions/truncNormModel/popgrowth_stanmcmc_", spp, ".RDS", sep=""))
  keeps <- which(tmp_data$Parameter %in% params)
  tmp_clim <- tmp_data[keeps, ]
  tmp_clim[,"Parameter"] <- rep(clim_covs2, each=3000)
  tmp_agg <- ddply(tmp_clim, .(Parameter), summarise,
                   qbmvalue = median(value))
  tmp_agg2 <- tmp_agg[which(tmp_agg$Parameter %in% clim_mains), ]
  tmp_agg2$species <- spp
  tmp_agg2$model <- "qbm"
  colnames(tmp_agg2) <- tolower(colnames(tmp_agg2))
  qbm_parms <- rbind(qbm_parms,
                     tmp_agg2[,c("species", "model", "parameter", "qbmvalue")])
}


####
##  Format data, combine, and plot
####
growth_parms <- growth_parms[2:nrow(growth_parms), ]
growth_parms$vitalrate <- "growth"
surv_parms <- surv_parms[2:nrow(surv_parms), ]
surv_parms$vitalrate <- "surv"
rec_parms <- rec_parms[2:nrow(rec_parms), ]
rec_parms$vitalrate <- "rec"
ipm_parms <- rbind(growth_parms, surv_parms, rec_parms)

qbm_parms <- qbm_parms[2:nrow(qbm_parms), ]
qbm_parms$vitalrate <- "growth"
vitals <- c("surv", "rec")
qbmalone <- qbm_parms
for(dov in vitals){
  tmp <- qbmalone
  tmp$vitalrate <- dov
  qbm_parms <- rbind(qbm_parms, tmp)
}

ipm_parms <- ipm_parms[,c("species","parameter","value","vitalrate")]
qbm_parms <- qbm_parms[,c("species","parameter","qbmvalue","vitalrate")]
all_ests <- merge(ipm_parms, qbm_parms, by = c("species", "parameter", "vitalrate"))

# Calculate correlation for each group
cors <- ddply(all_ests, c("species", "vitalrate"), summarise, 
              cor = round(cor(value, qbmvalue), 2))

ggplot(all_ests, aes(x=qbmvalue, y=value))+
  geom_point(size=3)+
  geom_smooth(method="lm", color="black", fill="grey")+
  facet_grid(species~vitalrate)+
  geom_text(data=cors, aes(label=paste("r = ", cor, sep="")), x=-1, y=1, size=4)+
  xlab("QBM Estimate")+
  ylab("IPM Estimate")+
  theme_bw()

setwd("~/Repos/MicroMesoForecast/manuscript/")
```


\pagebreak{}

References
----------
