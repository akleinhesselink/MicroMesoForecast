---
layout: 12pt
header-includes:
   - \usepackage{lineno}
   - \linenumbers
   - \usepackage{setspace}
   - \usepackage{sectsty}
   - \doublespacing
   - \usepackage{todonotes}
   - \usepackage[document]{ragged2e}
   - \usepackage{times}
bibliography: ~/Dropbox/Bibliography/MicroMeso.bib
csl: components/ecology.csl

## rmarkdown render options
output:
  pdf_document:
    fig_caption: true
    keep_tex: false
fontsize: 12pt
geometry: margin=1in
linkcolor: black
urlcolor: black

---

\textsf{\LARGE{\textbf{Do we need demographic data to forecast the state of plant populations?}}}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}

\vspace{1em}

\textsf{\normalsize{\textbf{Andrew T. Tredennick\textsuperscript{1}\footnote{Corresponding author: E-mail: atredenn@gmail.com}, Mevin B. Hooten\textsuperscript{2,3,4}, and Peter B. Adler\textsuperscript{1}}}}

\vspace{1em}

\textsf{\textit{\footnotesize{\textsuperscript{1}Department of Wildland Resources and the Ecology Center, 5230 Old Main Hill, Utah State University, Logan, Utah 84322, USA; \textsuperscript{2}U.S. Geological Survey, Colorado Cooperative Fish and Wildlife Research Unit, Department of Fish, Wildlife and Conservation Biology, Colorado State University, Fort Collins, CO 80523-1403, USA; \textsuperscript{3}Department of Fish, Wildlife, and Conservation Biology, Colorado State University, Fort Collins, CO 80523 USA}; \textsuperscript{4}Department of Statistics, Colorado State University, Fort Collins, CO 80523 USA}}


\allsectionsfont{\normalfont\sffamily\bfseries}
\renewcommand*{\thefootnote}{\arabic{footnote}}
\setcounter{footnote}{0}

\rule{\textwidth}{1pt}


```{r libraris, include=FALSE}
library(ggplot2)
library(plyr)
library(gridExtra)
library(reshape2)
library(xtable)
library(ggmcmc)
```

```{r caching, include=FALSE}
library("methods")
library("knitr")
basename <- "manuscript"
opts_chunk$set(fig.path = paste("components/figure/", basename, "-", sep=""),
               cache.path = paste("components/cache/", basename, "/", sep=""))
opts_chunk$set(cache = 2)
opts_chunk$set(tidy=FALSE, warning=FALSE, message=FALSE, 
               comment = NA, verbose = TRUE, echo=FALSE)

# PDF-based figures
opts_chunk$set(dev='pdf')
```


```{r plot-options, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
               "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

opts_chunk$set(dev='pdf', dev.args=c(version="1.3"))

```

Summary
-------

**1.** Rapid environmental change has generated growing interest in forecasts of future population trajectories.
Traditional population models, typically built using detailed demographic observations from one study site, can address the impacts of environmental change at one location, but are difficult to scale up to the landscape and regional scales relevant to management decisions.

**2.** An alternative is to build models using population-level data that are much easier to collect over broad spatial scales than individual-level data.
However, it remains unclear if models built using aggregated individual-level data adequately capture the effects of density-dependence and environmental forcing that are necessary to generate skillful forecasts. 

**3.** Here, we test the consequences of aggregating individual responses when forecasting the population states and trajectories of four perennial grass species in a semi-arid grassland in Montana, USA.
We parameterized two population models for each species, one based on individual-level data (survival, growth and recruitment) and one on population-level data (percent cover), and compared their forecasting skill and forecast horizons with and without the inclusion of climate covariates.
For both models we used Bayesian ridge regression to identify the optimal predictive model in terms of climate covariate strengths. 

**4.** Without climate effects included, we found no significant difference between the forecasting skill of models based on individual-level data and models based on population-level data.
Climate effects were weak and caused only slight increases in forecasting skill.
Increases in skill were similar between model types except for one species where forecast accuracy from the individual-level model was significantly higher than the accuracy from an equivalent population-level model.

**5.** *Synthesis.* For our focal species at this particular location, and using our particular statistical models, demographic data was generally unnecessary to achieve skillful forecasts, though for certain species forecast skill can be gained by using demographic data linked to climate covariates.
We conclude that models based on aggregated individual-level data offer a practical alternative to data-intensive demographic models when species do not respond strongly to interannual variation in weather, but when modeling species that do respond to climate drivers, demographically-based models can generate more skillful forecasts.

\textsf{\textbf{Key-words:}} forecasting, climate change, grassland, integral projection model, population model, statistical regularization, ridge regression

Introduction
------------

Perhaps the greatest challenge for ecology in the 21st century is to forecast the impacts of environmental change [@Clark2001; @Petchey2015]. Forecasts require sophisticated modeling approaches that fully account for uncertainty and variability in both ecological process and model parameters [@Luo2011a; but see @Perretti2013a for an argument against modeling the ecological process]. The increasing statistical sophistication of population models [@Rees2009] makes them promising tools for predicting the impacts of environmental change on species persistence and abundance. But reconciling the scales at which population models are parameterized and the scales at which environmental changes play out remains a challenge [@Clark2010; @Freckleton2011; @Queenborough2011; @Clark2012]. The problem is that most population models are built using data from a single study site because collecting those data, which involves tracking the fates of individuals plants, is so difficult. The resulting models cannot be applied to the landscape and regional scales relevant to decision-making without information about how the fitted parameters respond to spatial variation in biotic and abiotic drivers [@SÃ¦ther2007]. The limited spatial extent of individual-level demographic datasets constrains our ability to use population models to address applied questions about the consequences of climate change.

<!--
The inability of most population models to address landscape-scale problems may explain why land managers and conservation planners have embraced species distribution models (SDMs) [see @Guisan2005 for a review]. SDMs typically rely on easy-to-collect presence/absence data [but see @Clark2014 for new methods] and remotely-sensed environmental covariates that allow researchers to model large spatial extents [e.g., @Maiorano2013]. Thus, it is relatively straightforward to parameterize and project SDMs over landscapes and regions. However, the limitations of SDMs are well known [@Pearson2003; @Elith2009; @Araujo2012]. Ideally, researchers would provide managers with landscape-scale population models, combining the extent of SDMs with information about dynamics and species abundances [@Schurr2012; @Merow2014].  
-->

Aggregate measures of population status, rather than individual performance, offer an intriguing alternative for modeling populations [@Clark2004; @Freckleton2011]. Population-level data cannot provide inference about demographic mechanisms, but might be sufficient for modeling future population states, especially since such data are feasible to collect across broad spatial extents [e.g., @Queenborough2011]. The choice between individual and population-level data involves a difficult trade-off: while individual-level data leads to more mechanistic models, population-level data can lead to models that can be applied over greater spatial and temporal extents because the data are easier to collect over large spatial scales. An open question is how much forecasting skill is lost when we build models based on population rather than individual-level data.

To date, most empirical population modelers have relied on individual-level data, with few attempts to capitalize on population-level measures. An important exception was an effort by @Taylor2004 to model the population growth rate of an invasive species to identify the best strategies for invasion control. They used a "density-structured" model where the state variable is a discrete density state rather than a continuous density measure. Such models do not require individual-level demographic data and can adequately describe population dynamics. Building on @Taylor2004, @Freckleton2011 showed that density-structured models compare well to continuous models in theory, and @Queenborough2011 provide empirical evidence that density-structured models are capable of reproducing population dynamics at landscape spatial scales, even if some precision is lost when compared to fully continuous models. However, previous tests of density-structured models have yet to assess their ability to forecast out-of-sample observations, and they have not included environmental covariates, which is necessary to make forecasts of population responses to climate change.

Addressing climate change questions with models fit to population-level data is potentially problematic. It is individuals, not populations, that respond to climate variables [@Clark2012]. Ignoring this fact amounts to an "ecological fallacy", where inference about the individual relies on statistical inference on the group [@PIANTADOSI1988]. Population growth (or decline) is the outcome of demographic processes such as survival, growth, and recruitment that occur at the level of individual plants. Climate can affect each demographic process in unique, potentially opossing, ways [@Dalgleish2011]. These unique climate responses may be difficult to resolve in statistical models based on population-level data where demographic processes are not identifiable. If important climate effects are missed because of the aggregation inherent in in population-level data, then population models built with such data will make uninformative or unreliable forecasts.

Here, we compare the forecasting skill of statistical and population models based on aggregated, population-level data with models based on individual-level data. We used a demographic dataset that tracks the fates of individual plants from four species over 14 years to build two kinds of single-species population models, traditional models using individual growth, survival, and recruitment data and alternative models based on basal cover. We use the models to answer two questions: (1) Can population models fit using aggregated individual-level data (percent cover) produce forecasts as skillful as those from models fit to demographic data? 
And (2) Can population models fit using aggregated data adequately capture the influence of climate on population growth and, in turn, produce forecasts as skillful as those from models fit to demographic data? 


Materials and Methods
---------------------
### Study site and data
Our demographic data come from the Fort Keogh Livestock and Range Research Laboratory in eastern Montana's northern mixed prairie near Miles City, Montana, USA ($46^{\circ}$ 19' N, $105^{\circ}$ 48' W). The dataset is freely available on Ecological Archives[^link] [@Anderson2011], and interested readers should refer to the metadata for a complete description. The site is about 800 m above sea level and mean annual precipitation (1878-2009) is 334 mm, with most annual precipitation falling from April through September. The community is grass-dominated, and we focused on the four most abundant grass species: \emph{Bouteloua gracilis} (BOGR), \emph{Hesperostipa comata} (HECO), \emph{Pascopyrum smithii} (PASM), and \emph{Poa secunda} (POSE) (Fig. 1). *B. gracilis* is a warm-season perennial grass, whereas *H. comata*, *P. smithii*, and *P. secunda* are cool-season perennial grasses. All species typically begin growth in the early spring, reach maximum growth and flower in early to mid summer (May-June), and disperse seed in mid to late summer (July-September). 

[^link]: http://esapubs.org/archive/ecol/E092/143/

From 1932 to 1945 individual plants were identified and mapped annually in 44 1-$\text{m}^2$ quadrats using a pantograph. The quadrats were distributed among six pastures, each assigned a grazing treatment of light (1.24 ha/animal unit month), moderate (0.92 ha/aum), and heavy (0.76 ha/aum) stocking rates (two pastures per treatment). In this analysis we account for potential differences among the grazing treatments, but do not focus on grazing$\times$climate interactions. The annual maps of the quadrats were digitized and the fates of individual plants tracked and extracted using a computer program [@Lauenroth2008; @Chu2014a]. The permanent quadrats have not been relocated, but their distribution in six different pastures means the data represent a broad spatial distribution for the study area. Daily climate data are available for the duration of the data collection period (1932 - 1945) from the Miles City airport, Wiley Field, 9 km from the study site.

We modeled each grass population based on two levels of data: individual and quadrat. The individual data is the "raw" data. For the quadrat-level we data we simply sum individual basal cover for each quadrat by species. This is equivalent to a near-perfect census of quadrat percent cover because previous analysis shows that measurement error at the individual-level is small [@Chu2014]. Based on these two datasets of 13 year-to-year transitions, we can compare population models built using individual-level data and aggregated, quadrat-level data. At the individual level we explicitly model three vital rates: growth, survival, and recruitment. At the quadrat level we model population growth as change in percent cover of quadrats with non-zero cover in year *t* and in year *t-1*. For modeling population growth at the quadrat level we ignore within-quadrat extirpation and colonization events because they are very rare in our time series ($N=16$ and $N=13$, respectively, across all species). Sample sizes for each species and vital rate model are shown in Table 1. Given the relatively broad spatial distribution of the quadrats we are studying, it is safe to assume that these events are in fact rare enough to be ignored for our purposes.

All R code and data necessary to reproduce our analysis is archived on GitHub as release v1.0[^revnote] (http://github.com/atredennick/MicroMesoForecast/releases). That stable release will remain static as a record of this analysis, but subsequent versions may appear if we update this work. We have also deposited the v1.0 release on Dryad (*link here after acceptance*).

[^revnote]: *Note to reviewers*: so that v1.0 will be associated with the published version of the manuscript, we have released v0.2 to be associated with this review version.

### Stastical models of vital rates
At both levels of inference (individual and quadrat), the building blocks of our population models are vital rate regressions. For individual-level data, we fit regressions for survival, growth, and recruitment for each species. At the quadrat-level, we fit a single regression model for population growth. We describe the statistical models separately since fitting the models required different approaches. For both model types, we fit vital rate models with and without climate covariates. Models with climate effects contain five climate covariates that we chose \emph{a priori} based on previous model selection efforts using these data (Chu et al. *in press*) and expert advice (Lance Vermeire, *personal communication*): "water year" precipitation at \emph{t}-2 (lagppt); April through June precipitation at \emph{t}-1 and \emph{t} (ppt1 and ppt2, respectively) and April through June temperature at \emph{t}-1 and \emph{t} (TmeanSpr1 and TmeanSpr2, respectively), where \emph{t}-1 to *t* is the transition of interest. We also include interactions among same-year climate covariates (e.g., ppt1 $\times$ TmeansSpr1), resulting in a total of seven climate covariates.

We fit all models using a hierarchical Bayesian approach. The models are fully descibed in Appendix A, so here we focus on the main process and the model likelihood. For the likelihood models, $\textbf{y}^X$ is always the relevant vector of observations for vital rate *X* (*X* = *S*, *G*, *R*, or *P*) for survival, growth, recruitment, or population growth). For example, $\textbf{y}^S$ is a vector of 0's and 1's indicating whether a genet survives from *t* to *t+1*, or not. All model parameters are species-specific, but we omit subscripts for species in model descriptions below to reduce visual clutter. For brevity, we only describe models with climate covariates included, but models without climate covariates are exactly the same as the models described below, just without the climate effects.

#### Vital rate models at the individual level
We used logistic regression to model survival probability ($s$) of a genet:

\vspace{-3em}
\begin{align}
\textbf{y}^{S} &\sim \text{Bernoulli}(\textbf{s}) \\
\text{logit}[s(x,\textbf{z}_t,w)] &= \beta_{0,t} + \beta_{s,t}x + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c + \beta_{d,1} w + \beta_{d,2} (xw)
\end{align}
\vspace{-3em}

where $x$ is the log of genet basal area, $\beta_{0,t}$ is a year specific intercept intercept, $\beta_Q$ is the random effect of quadrat group location, $\beta_{s,t}$ is the year-specific slope parameter for size, **z** is a vector of *i* climate covariates specific to year *t*, $\boldsymbol{\beta}_c$ is a vector of fixed climate effects of length *i*, $\beta_{d,1}$ is the effect of intraspecific crowding experienced by the focal genet (*w*), and $\beta_{d,2}$ is a size by crowding ($xw$) interaction effect. 

We modeled growth as a Gaussian process describing genet size at time $t+1$ as a function of size at $t$ and climate covariates:

\vspace{-3em}
\begin{align}
\textbf{y}^G &\sim \text{Normal}(\boldsymbol{\mu}, \sigma^2_{x,t}) \\
\mu(x,\textbf{z}_t,w) &= \beta_{0,t} + \beta_{s,t}x + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c + \beta_{d,1} w + \beta_{d,2} (xw)
\end{align}
\vspace{-3em}

where $\mu(x,\textbf{z}_t,w)$ is log of predicted genet size at time *t* + 1, and all other parameters are as described for the survival regression. We capture non-constant error variance in growth by modeling the variance around the growth regression ($\sigma^2_{x,t}$) as a nonlinear function of predicted genet size:

\vspace{-3em}
\begin{align}
\sigma^2_{x,t} = a \, \text{exp}[b \times \mu(x,\textbf{z}_t,w)]
\end{align}
\vspace{-3em}

where $\mu(x,\textbf{z}_t,w)$ is log of predicted genet size predicted from the growth regression (Eq. 4), and *a* and *b* are constants.

Our data allows us to track new recruits, but we cannot assign a specific parent to new genets. 
Therefore, we model recruitment at the quadrat level.
We assume the number of individuals, $y^{R}$, recruiting at time $t+1$ in quadrat q follows a negative binomial distribution:

\vspace{-3em}
\begin{align}
y^{R}_{q,t+1} \sim \text{NegBin}(\lambda_{q,t+1},\phi)
\end{align}
\vspace{-3em}

where $\lambda$ is the mean intensity and $\phi$ is the size parameter. We define $\lambda$ as a function of quadrat composition and climate in the previous year:

\vspace{-3em}
\begin{align}
\lambda_{q,t+1} = C'_{q,t} \, \text{exp}\left(\beta_{0,t} + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c + \beta_{d}\sqrt{C'_{q,t}}\right)
\end{align}
\vspace{-3em}

where $C'$ is effective cover ($\text{cm}^2$) of the focal species in quadrat $q$, and all other terms are as in the survival and growth regressions.
Effective cover is a mixture of observed cover ($C$) in the focal quadrat ($q$) and the mean cover across the entire group ($\bar{C}$) of $Q$ quadrats in which $q$ is located:

\vspace{-3em}
\begin{align}
C'_{q,t} = pC_{q,t} + (1-p)\bar{C}_{Q,t}
\end{align}
\vspace{-3em}

where $p$ is a mixing fraction between 0 and 1 that is estimated within the model.


#### Population model at the quadrat level
The statistical approach used to model aggregated data depends on the type of data collected. We have percent cover data, which can easily be transformed to proportion data. An obvious choice for fitting a linear model to proportion data is beta regression because the support of the beta distribution is [0,1], not including true zeros or ones. However, when we used fitted model parameters from a beta regression in a quadrat-based population model, the simulated population tended toward 100% cover for all species. We therefore chose a modeling approach based on a truncated log-normal likelihood. The model for quadrat cover change from time $t$ to $t+1$ is

\vspace{-3em}
\begin{align}
\textbf{y}^{P} &\sim \text{LogNormal}(\mu(x,\textbf{z}_t), \sigma^2) \text{T}[0,1] \\
\mu(x,\textbf{z}_t) &= \beta_{0,t} + \beta_{s,t}x + \beta_Q + \textbf{z}'_t \boldsymbol{\beta}_c
\end{align}
\vspace{-3em}

where $\mu(x,\textbf{z}_t)$ is the log of proportional cover in quadrat $q$ at time $t+1$, and all other parameters are as in the individual-level growth model (Eq. 4) except that *x* now represents log of proportional cover. The log normal likelihood includes a truncation (T[0,1]) to ensure that predicted values do not exceed 100% cover. 

### Model fitting and stastical regularization
####  Model fitting
Our Bayesian approach to fitting the vital rate models required choosing appropriate priors for unknown parameters and deciding which, if any, of those priors should be hierarchical. We decided to fit models where all terms were fit by species. Within a species, we fit yearly size effects and yearly intercepts hierarchically where year-specific coefficients were drawn from global distributions representing the mean size effect and intercept. Quadrat random effects were also fit hierarchically, with quadrat offsets being drawn from distributions with mean zero and a shared variance term (independent Gaussian priors, Appendix A). Climate effects were modeled as independent covariates whose prior distributions were determined by statistical regularization (see **Statistical regularization: Bayesian ridge regression** below).

All of our analyses (model fitting and simulating) were conducted in R [@R2013]. We used the 'No-U-Turn' MCMC sampler in Stan [@stan2014]  to estimate the posterior distributions of model parameters using the package 'rstan' [@rstan2014]. We obtained posterior distributions for all model parameters from three parallel MCMC chains run for 1,000 iterations after discarding an initial 1,000 iterations. Such short MCMC chains may surprise readers more familiar with other MCMC samplers (i.e. JAGS or WinBUGS), but the Stan sampler is exceptionally efficient, which reduces the number of iterations needed to achieve convergence. We assessed convergence visually and made sure scale reduction factors for all parameters were less than 1.1. For the purposes of including parameter uncertainty in our population models, we saved the final 1,000 iterations from each of the three MCMC chains to be used as randomly drawn values during population simulation. We report the posterior mean, standard deviation, and 95% Bayesian Credible Intervals for every parameter of each model for each species in Appendix B.

#### Statistical regularization: Bayesian ridge regression
For models with climate covariates, our objective is to model the response of our focal grass species to interannual variation in climate, even if those responses are weak.
Therefore, we avoid selecting among models with all possible combinations of climate covariates, and instead use Bayesian ridge regression to regulate, or constrain, the posterior distributions of each climate covariate [@Hooten2015].
Ridge regression is a specific application of statistical regularization that seeks to optimize model generality by trading off bias and variance.
As the name implies, statistical regularization involves the use of a regulator that constrains an optimization.
The natural regulator in a Bayesian application is the prior on the coefficient of interest.
Each of our statistical models includes the effects of climate covariates via the term $\textbf{z}'_t \boldsymbol{\beta}_c$ with prior $\boldsymbol{\beta}_c \sim \text{Normal}(\boldsymbol{\mu}_{\beta_c}, \sigma_{\beta_c}^2)$.
Since we standardized all climate covariates to have mean zero and variance one, we can set $\boldsymbol{\mu}_{\beta_c} = 0$ and let $\sigma_{\beta_c}^2$ serve as the regulator that can shrink covariates toward zero -- the smaller the prior variance, the more the posteriors of $\boldsymbol{\beta}_c$ are shrunk toward zero, and the stronger the penalty [@Hooten2015].

To find the optimal penalty (i.e., optimal value of the hyperparameter $\sigma_{\beta_c}^2$), we fit each statistical model with a range of values for $\sigma_{\beta_c}^2$ and compared predictive scores from leave-one-year-out cross-validation.
We performed the grid search over 24 values of $\sigma_{\beta_c}^2$, ranging from $\sigma_{\beta_c}^2 = 0.01$ to $\sigma_{\beta_c}^2 = 2.25$.
For each statistical model and each species we fit $13\times24=312$ models (13 years to leave out for cross-validation and 24 values of $\sigma_{\beta_c}^2$) -- a total of 4,992 models.
We calculated the log pointwise predictive density (*lppd*) to score each model's ability to predict the left-out data.
Thus, for training data $y_{train}$ and held-out data $y_{hold}$ at a given value of  $\sigma_\theta^2$ across all MCMC samples $s=1,2,...,S$ and all hold outs of data from year *t* to year *T*, and letting $\theta$ represent all unknowns, *lppd* is

\vspace{-3em}
\begin{align}
\text{lppd}_{\text{CV}} = \sum_{t=1}^T \text{log}_e \int [y_{t,hold}|\theta][\theta|y_{train}]d\theta,
\end{align}
\vspace{-3em}

and computed as

\vspace{-3em}
\begin{align}
\sum_{t=1}^T \text{log}_e \left(\frac{1}{S} \sum^S_{s=1}(y_{t,hold}|\theta_{ts})  \right).
\end{align}
\vspace{-3em}

We chose the optimal prior variance for each species-statistical model combination as the one that produced the highest *lppd* and then fit each species-statistical model combination using the full data set for each species and the optimal prior variance.

### Population models
With the posterior distribution of the vital rate statistical models in hand, it is straightforward to simulate the population models. We used an Integral Projection Model (IPM) to model populations based on individual-level data [@Ellner2006] and a quadrat-based version of an individually-based model (Quadrat-Based Model, QBM) to model populations based on quadrat-level data. We describe each in turn.

#### Integral projection model
We use a stochastic IPM [@Rees2009] that includes the climate covariates from the vital rate statistical models. In all simulations we ignore the random year effects so that interannual variation is driven solely by climate. We fit the random year effects in the vital rate regressions to avoid over-attributing variation to climate covariates. Our IPM follows the specification of @Chu2015 where the population of species _j_ is a density function $n(u_{j},t)$ giving the density of sized-_u_ genets at time _t_. Genet size is on the natural log scale, so that $n(u_{j},t)du$ is the number of genets whose area (on the arithmetic scale) is between $e^{u_{j}}$ and $e^{u_{j}+du}$. The density function for any size _v_ at time $t+1$ is

\vspace{-3em}
\begin{align}
n(v_{j},t+1) = \int_{L_{j}}^{U_{j}} k_{j}(v_{j},u_{j},\bar{w_{j}}(u_{j}))n(u_{j},t)
\end{align}
\vspace{-3em}

where $k_{j}(v_{j},u_{j},\bar{w_{j}})$ is the population kernel that describes all possible transitions from size $u$ to $v$ and $\bar{w_{j}}$ is a scalar representing the average intraspecific crowding experienced by a genet of size $u_j$ and species $j$. The integral is evaluated over all possible sizes between predefined lower (_L_) and upper (_U_) size limits that extend beyond the range of observed genet sizes.

Since the IPM is spatially-implicit, we cannot calculate neighborhood crowding for specific genets ($w_{ij}$). Instead, we use an approximation ($\bar{w_{j}}$) that captures the essential features of neighborhood interactions [@Adler2010]. This approximation relies on a 'no-overlap' rule for conspecific genets to approximate the overdispersion of large genets in space [@Adler2010].

The population kernel is defined as the joint contributions of survival (_S_), growth (_G_), and recruitment (_R_):

\vspace{-3em}
\begin{align}
k_{j}(v_{j},u_{j},\bar{w_{j}}) = S_j(u_j, \bar{w_{j}}(u_{j}))G_j(v_{j},u_{j},\bar{w_{j}}(u_{j})) + R_j(v_{j},u_{j},\bar{w_{j}}),
\end{align}
\vspace{-3em}

which means we are calculating growth (_G_) for individuals that survive (_S_) from time _t_ to _t+1_ and adding in newly recruited (_R_) individuals of an average sized one-year-old genet for the focal species. Our stastical model for recruitment (_R_, described above) returns the number of new recruit produced per quadrat. Following previous work [@Adler2012; @Chu2015], we assume that fecundity increases linearly with size ($R_j(v_{j},u_{j},\bar{w_{j}}) = e^{u_j}R_j(v_{j},\bar{w_{j}})$) to incorporate the recruitment function in the spatially-implicit IPM.

We used random draws from the final 1,000 iterations, thinned by 10, from each of three MCMC chains to carry-through parameter uncertainty into our population models. At each time step, we randomly selected climate covariates from one of the 14 observed years. Then, we drew the full parameter set (climate effects and density-dependence fixed effects) from a randomly selected MCMC iteration. Relatively unimportant climate covariates (those that broadly overlap 0) will have little effect on the mean of the simulation results, but can contribute to their variation. Since our focus was on the contribution of density dependence and climate covariates to population states, we set the random year effects and the random group effects to zero. 

#### Quad-based model
To simulate our quad-based model (QBM), we simply iterate the quadrat-level statistical model (Eqs. 9-10). We use the same approach for drawing parameter values as described for the IPM. After drawing the appropriate parameter set, we calculate the mean response (log cover at *t+1* = $\mu_{t+1}$) according to Eq. 10. We then make a random draw from a [0,1] truncated lognormal distribution with mean equal to $\mu_{t+1}$ from Eq. 10 and the variance estimate from the fitted model. We can then project the model forward by drawing a new parameter set (unique to climate year and MCMC iteration) at each timestep. As with the IPM, random year effects are ignored for all simulations.

### Model validation
To test each model's ability to forecast population states we made out-of-sample predictions using leave-one-year-out cross validation. For both levels of modeling and for models with and without climate covariates, we fit the vital rate models using observations from all years except one, and then used those fitted parameters in the population models to perform a one-step-ahead forecast for the year whose observations were withheld from model fitting. Within each observation year, several quadrats were sampled. We made predictions for each observed quadrat in the focal year, initializing each simulation with cover in the quadrat the previous year. Since we were making quadrat-specific predictions, we incorporated the group random effect on the intercept for both models. We repeated this procedure for all 13 observation years, making 100 one-step-ahead forecasts for each quadrat-year combination with parameter uncertainty included via random draw from the MCMC chain as described above. Random year effects were set to zero since year effects cannot be assigned to unobserved years. 

This cross-validation procedure allowed us to compare accuracy and precision of the two modeling approaches (IPM versus QBM) with and without climate covariates. We first calculated the median predicted cover across the 100 simulations for each quadrat-year and then calculated forecast skill as the correlation ($\rho$) between forecasts and observations. We compared $\rho$ between model types and within model types between models with and without climate covariates using a one-sided *t* test with adjusted degrees of freedom following @Wilcox2009 and standard errors calculated using the HC4 estimator of @Cribari-Neto2004. Statistical tests for differences between $\rho$ were conducted using R functions from @Ye2015a.

### Forecast horizons
An important feature of any forecasting model is the rate at which forecast skill declines as the time between an observation and a forecast increases; the so-called ecological forecast horizon [@Petchey2015].
To assess the forecast horizons of our models, we iniate the model with the population state at some time *t* and make sequential forecasts of the population at times $t+1, t+2, \dots, t+T$ where *T* is the maximum number of years between the initial year and the final year in our observations.
For example, if we initialize the model with percent cover in 1940, we are able to make five forecasts up to the year 1945.
Models are not re-initialized with observations between years.
Thus, in our current example, the model forecast for percent cover in 1941 has a forecast horizon of one year, the forecast in 1942 has a forecast horizon of two years, and so on.
We ran these simulations for all model types (IPM with/without climate; QBM with/without climate) using mean parameter values for all possible initial years.
Then, for a given forecast horizon, we averaged the correlation between forecasts and observations.
Note that these forecasts are all made using in-sample data since we used model fits from the full data set.
Nonetheless, these simulations offer insight into the differences between model forecast horizons.

<!--
### Testing sensitivity to climate covariates
With our fitted and validated models in hand, we ran simulations for each model type (IPM and QBM) under four climate perturbation scenarios: (1) observed climate, (2) precipitation increased by 1%, (3) temperature increased by 1%, and (4) precipitation and temperature increased by 1%. We ran the simulations for 2,500 time steps, enough to estimate equilibrium cover after discarding an initial 500 time steps as burn-in. Each simulation was run under two parameter scenarios: (1) using mean parameter estimates and (2) using randomly drawn parameters from the MCMC chain. We use (1) to detect the overall sensitivity of equilibrium cover to climate, and we use (2) to show the impact of model and parameter uncertainty on forecast precision.

As an effort to identify potential discrepencies between IPM and QBM forecasts, we also ran simulations designed to quantify the sensitivities of individual and combined vital rates to climate for the IPM. Specifically, we ran simulations for the above climate scenarios, but applied the perturbed climate covariates to survival, growth, or recruitment vital rates individually and in pairwise combinations. This allowed us to isolate the vital rate(s) most sensitive to climate. For this analysis, we used mean parameter estimates to reduce the sources of uncertainty in the sensitivity estimates.

We expected the IPM to produce more accurate and precise forecasts due to either (1) the smaller sample size of the quadrat level data sets compared to the individual level data sets, leading to larger parameter uncertainty for the QBM, or (2) the QBM climate effects being weakly associated with one or more vital rate climate effects at the individual level. To assess the impact of sample size on QBM parameter uncertainty we refit the QBM statistical model (Eqs. 9-10) after removing sets of 2, 5, 10, and 15 quadrats. We fit 10 models at each level of quadrat removal (2, 5, 10, 15 quadrats), removing a different randomly selected set of quadrats for each fit. We calculated the standard deviation of climate main effects (pptLag, ppt1, ppt2, TmeanSpr1, and TmeanSpr2) for each model and averaged those over replicates within each set of quadrat removals. This allowed us to regress parameter uncertainty against sample size. 

To deterime if the QBM climate effects are correlated with climate effects for each vital rate model in the IPM, we simply regressed the QBM climate coefficients against each vital rate model's climate coefficients and calculated Pearson's $\rho$. Strong correlations indicate the QBM is capable of detecting climate effects associated with individual vital rates. A weak correlation indicates the QBM "misses" the climate effect on a particular vital rate.
-->

Results
-------
Both the IPM and QBM generated skillful one-step-ahead forecasts for out-of-sample observations, with an average correlation between predictions and observations ($\rho$) of 0.# across all models (Fig. 2).
Without climate covariates, the accuracy of forecasts from the IPM were not statistically greater than the accuracy of forecasts from the QBM.
With climate covariates, the best out-of-sample predictive model (highest *lppd*) for each species and vital rate typically resulted from highly constrained priors on the climate effects (Fig. S1).
Thus, the posterior distributions of climate effects included in our models overlapped zero and generally shrunk toward zero, though for some species-vital rate combinations important effects (80% credible interval does not include zero) did emerge (Fig. 3). 
Despite the small effects, including climate covariates did increase the accuracy of forecasts for all species except *P. smithii* (Fig. 2).
However, increases in accuracy due to the inclusion of climate covariates were not significant (*P* > 0.05 for all comparisons of $\rho$ between climate and no-climate forecasts within model types; Fig. 2).
In only one case were IPM forecasts significantly more accurate than the QBM (Fig. 2): forecast accuracy of *P. secunda* percent cover from an IPM with climate covariates was greater than the accuracy from an equivalent QBM ($t_{(195)}$ = 1.72, *P* = 0.043).
The accuracy of both model's forecasts declined as the forecast horizon increased, but they did so at similar rates (Fig. 4).
The only exception is for *P. secunda* where forecast accuracy appears to slightly increase with forecast horizon, after an initial decrease from a forecast horizon of one year (Fig. 4).

<!--
### Comparison of forecast models


### Sensitivity of models to climate
The response of a population to climate change is a result of the aggregate effects of climate on individual vital rates. Since the IPM approach relies on vital rate regressions, we were able to quantify the sensitivity of each vital rate in isolation and in pairwise combinations. Across all species, climate covariates can have opposing effects on different vital rates (Fig. 3). Growth was the most sensitive vital rate for all species, showing a negative response to increased precipitation, and stronger positive response to increased temperature, and a mostly positive response when both climate factors are increased (Fig. 3). *B. gracilis* survival rates were sensitive to temperature, resulting in an increase in plant cover under increased temperature (Fig. 3a). In isolation, recruitment and survival were insensitive to climate factors for *H. comata* (Fig. 3b). Survival and recruitment of *P. smithii* were both sensitive, negatively, to temperature and precipitation (Fig. 3c). *P. secunda* equilibrium cover was sensitive to the climate effects on survival and recruitment, showing a negative effect on both vital rates for increased precipition, but a strong positive effect on survival with increased temperature (Fig. 3d). Equilibrium cover responded negatively when increased precipitation and temperature affect recruitment  (Fig. 3d). At least two of three vital rates were sensitive to climate for each species (Fig. 3).

### Sources of uncertainty in the QBM
Sample size had a relatively weak effect on QBM climate parameter uncertainty after the number of quadrats used in fitting exceeded about 10 (Fig. 5). Inverse-gaussian fits show that increasing sample size beyond the number of quadrats we used would result in diminishing returns in terms of parameter certainty (Fig. 5). 

Climate effects estimated from the QBM are most correlated with climate effects from the growth regression at the individual level (Fig. 6). In no case does the QBM statistical model have strong correlations across all three vital rates (Fig. 6). QBM climate effects were most weakly correlated with those from individual-level recruitment models for *B. gracilis*, *H. comata*, and *P. secunda* (Fig. 6a,b,d). For *P. smithii*, QBM climate effects showed no correlation with the survival model effects (Fig. 6c). 

### Model forecasts
Forecasts based on 1% climate changes were extremely uncertain when we considered model error and parameter uncertainty (Fig. 6; simulations with mean parameters are in Appendix D for comparison). As expected based on model validation (Table 1), QBM projections were more uncertain than IPM projections for all species except *P. smithiii* (Fig. 6). IPM forecasts for *P. smithiii* were very uncertain due to a very high instrinsic rate of recruitment combined with uncertainty in climate coefficients which lead to high recruitment boom years and subsequent busts when young plants suffer high mortality (Appendx C). When we included model error and parameter uncertainty, forecast changes in proportional cover always spanned a wide range of negative to positive values. In other words, neither model could predict whether a climate perturbation would increase or decrease equilibrium population size.
-->

Discussion
----------
Population models built using individual-level data allow inference on demographic processes, but they can only forecast future population states across the (typically limited) spatial extent of the observations. 
Population-level data are much easier to collect across broad spatial extents, so models built using such data offer an appealing alternative to traditional population models [@Queenborough2011]. 
However, density-structured models rely on the aggregation of individual-level data. 
This creates a potential problem if (1) such models inaccurately estimate density-dependence or (2) are to be used in a climate change context because it is individuals, not populations, that respond to climate [@Clark2012]. Can models based on population-level metrics generate forecasts that are as skillful as those generated from models based on individual-level data? Are models based on population-level metrics as sensitive to climate as models based on individual-level data? Do we need detailed demographic data to forecast the state of plant populations? 

Our comparison of a traditional, demographic population model without environmental forcing (the IPM) to an equivalent model inspired by density-structured models (the QBM) showed that, generally, IPM forecasts of out-of-sample plant population states were no more accurate than forecasts from the QBM (Fig. 2; `no-climate' bars).
We expected the IPM to out-perform the QBM since the IPM includes more mechanistic detail on the perennial plant life cycle, but this was not the case.
Thus, it appears that, without environmental forcing, the IPM and QBM generate equivalent forecasts.
Such a finding confirms theoretical [@Freckleton2011] and empirical work [@Queenborough2011] showing that density-structured models can be useful surrogates for demographic models when the goal is to estimate or forecast population states over large spatial extents.
Likewise, the equivalency of forecast accuracy between the IPM and QBM held for all four species, when climate covariates are not included, extending the generality of previous findings [e.g., @Taylor2004; @Queenborough2011].

While the models did not differ in forecast accuracy when only density-dependence was allowed to determine population dynamics, we expected that the inclusion of environmental forcing would elucidate the differences between the models.
Our expectation was the the IPM would outperform the QBM when we included climate covariates because interannual variation in weather can affect vital rates in unique ways [@Dalgleish2011].
Thus, estimates of climate effects on plant population growth may be biased or non-identifiable when the underlying statistical model is fit using population-level data that integrates over the potentially unique climate responses of individual vital rates.
However, IPM forecast accuracy was only significantly higher than the QBM for one species, *P. secunda* (Fig. 2, `climate' bars).
This result likely stems from the relatively weak climate effects in vital rate regressions (Fig. 3).
If climate effects on vital rates are weak, then models based on percent cover or density should fair well compared to models based on individual-level data so long as density-dependence is adequately estimated (see Fig. 2 and Freckleton et al. 2011).

Our naive expectation was that a single, relatively important climate effect in a vital rate regression would cause a discernable difference between IPM and QBM forecast skill because individual-level responses may be less identifiable from percent cover data [@Clark2012].
We actually found the opposite.
Survival or recruitment regressions for *B. gracilis*, *H. comata*, and *P. smithii* all included at least one relatively important climate effect, which we *a posterior* defined as a standardized coefficient whose 80% credible interval does not overlap zero (Fig. 3).
Yet, only the forecast skill for *P. secunda* differed between the IPM and QBM (Fig. 2).
Our explanation is that while at least one vital regression for the other three species included a relatively strong climate effect, only *P. secunda* had a vital rate regression with several smaller climate effects all trending in the same direction (Fig. 3).
Thus, it appears that the estimation of several small effects, rather than a single relatively large effect, can lead to increased forecast skill.

The higher accuracy of the IPM with climate for *P. secunda*  highlights the superiority of contemporary model and variable selection approaches such as ridge regression and LASSO over techniques that lead to excluding "non-significant" effects from final models.
Especially in a Bayesian forecasting framework, ridge regression allows researchers to include forcing variables that we know are changing (e.g., temperature and precipitation) in final models even if the estimated effects are relatively small or even deemed unimportant due to noisy data, out of which it is more difficult to estimate effects on interannual variation.
Likewise, if a species is truly unresponsive to a given climate variable, statistical regularization techniques will shrink the mean and variance of a covariate estimate to zero [@Hooten2015].
No amount of statistical "machismo" during the model fitting stage can make up for including the appropriate candidate covariates, which we attempted to do based on our knowledge of this semi-arid plant community.
However, the climate covariates we chose required aggregating daily weather data over specific time periods.
It may be that we chose the wrong time periods over which to aggregate.
New methods using functional linear models (or splines) may offer a data-driven approach for identifying the appropriate time periods over which to aggregate to produce a tractable set of candidate climate variables [@Teller2016].

We also expected IPM forecast accuracy to decline at a lower rate than the QBM as the forecast horizon increased.
Indeed, many have argued that more mechanistic models produce better predictions, especially under novel conditions [@Evans2012b; @Schindler2015b].
Likewise, the IPM explicitly models the processes of recruitment and survival that may be poorly represented in the QBM since recruitment and survival mainly affect small plants that contribute little to overall changes in percent cover.
But the addition and subtraction of small plants can have large effects on population growth over time and potentially lead to a longer forecast horizon for models that better represent the plant life cycle.
We found no evidence for a difference between the IPM and QBM forecast horizons (Fig. 4).
Similar forecast horizons should be expected if both models adequately capture density-dependence and environmental forcing is negligble, as is the case for our models (Fig. 2).
In fact, only the forecast horizons for *P. secunda* noticeably differ (Fig. 4), and that is also the only species where we found the IPM to outperform the QBM when we included climate effects. 

In conclusion, we found that demographic data was generally unneccesary to generate skillful forecasts of plant population states.
Such a finding is contrary to our expectations, but in agreement with recent theoretical [@Freckleton2011] and emprical work [@Queenborough2011].
However, when we included climate covariates, we did achieve more skillful forecasts from the IPM for one species, *P. secunda*, that appears to respond consistently, but weakly, to several climate variables.
Thus, we conclude that models based on population-level data, rather than individual-level data, may be adequate for forecasting the state of plant populations for species that do not respond consistently or strongly to climate.
Unfortunately, our analysis, where climate effects were relatively unimportant in vital rate regressions, did not allow us to sufficiently test our prediction that individual-level data is neccessary to generate skillful forecasts if different vital rates respond to climate in unique, potenially opposing, ways.
Nonetheless, our results are encouraging for the use of easy-to-collect percent cover for forecasting the state of plant populations.

<!---
### The importance of demographic data
Our comparison of a traditional, demographic population model (the IPM) with a model inspired by density-structured models (the QBM) showed that the IPM outperformed the QBM: the IPM was more accurate and precise than the QBM in out-of-sample cross validation (Table 1). The superiority of the IPM could reflect either differences in sample size or the effect of averaging over unique effects of climate on each individual-level vital rate. Although increasing sample size of quadrat percent-cover observations would be easy to do in the field, we found little evidence that it would lead to higher precision of climate coefficient estimates (Fig. 4). 

We did, however, find evidence that the QBM statistical model failed to identify climate dependence for some vital rates (Fig. 5). For no species were climate effects from the QBM strongly correlated with all three vital rates (Fig. 5). @Freckleton2011 acknowledge that averaging over complex stage dependence will lead to poorly specified models. This is analagous to our situation, but instead of averaging over complex life histories, we are averaging over complex climate dependence. Though our work here focused on plant species, this finding is applicable to any species with vital rates that respond uniquely to weather/climate.

Our interpretation is that the QBM is "missing" climate signals associated with at least one vital rate for each species. This leads to inaccurate and imprecise forecasts because the QBM statistical model struggles to explain variation due to climate variables that have positive and negative impacts on different vital rates. When this is the case, as it is for all our species to varying degrees (Fig. 3), forecasts from models based on population-level data will fail. Our result is consistent with related work on the importance of individual-level data to forecast population responses to exogenous drivers [@Clark2011; @Clark2011b; @Clark2012; @Galvan2014].

Detailed demographic data appears to be necessary to forecast climate change impacts on plant populations when vital rates have unique climate responses. How then can we build models to make forecasts for the landscape and regional scales beyond the scope of traditional population models [@Queenborough2011]? There are alternatives to density-structured models. For example, @Clark2011 use Forest Inventory and Analysis (FIA) data to parameterize a population model with multiple vital rates and climate dependence. Distributed efforts such as PlantPopNet (http://plantago.plantpopnet.com) will allow researchers to estimate variation around climate responses for widespread species by taking advantage of spatial variation in climate [e.g. @Doak2010]. Finally, new approaches on the horizon that leverage photo/video of plots and advanced object recognition algorithms [e.g. @Liu2014] will increase the efficiency of plant mapping and digitizing efforts.  

### The challenge of uncertainty

An important, but unexpected, result of our analysis was the great uncertainty in forecasts, even for our best model. The typical approach in ecology is to use point estimates of model parameters to project populations forward according to the specified model, usually allowing for some variability around the determinstic process [e.g. @Battin2007; @Jenouvrier2009; @Adler2012]. If we follow tradition and calculate the mean response to climate perturbation with only model error and interannual variation included, the IPM and the QBM produce opposing forecasts for three of four species (Fig. D1). It would be tempting to interpret this inconsistency as further evidence for the superiority of the IPM. However, if we introduce parameter uncertainty, the forecasts are actually indistinguishable (Fig. 6), though the IPM projections are generally more precise (consistent with our cross-validation results). The real story is that both models produce highly uncertain forecasts. For all species, the 90% quantiles of predicted changes in population size overlapped zero; we cannot even predict whether a change in precipitation or temperature will cause populations to increase or decrease. This result held when we tried perturbing climate by 10% and 20% as well.

Our results highlight the state of affairs in ecology when it comes to forecasting the impacts of climate change. The analysis we conducted here could be considered at the forefront of ecological forecasting with respect to the statistical approach employed (hierarchical Bayesian), the type of population model we used (density-dependent, stochastic IPM with parameter uncertainty), and the amount of high quality data we had at our disposal (14 years of individual-level data). Yet, model predictions proved so uncertain that any forecast, when bounded with model and parameter uncertainty, would be uninformative. 

How might we improve on this state of affairs? First, forecasts could be improved by matching the spatial scale of predictor variables with the spatial scale of observations. One of the major limitations of the models we fit here is that the climate data are collected at a larger scale than the individual-level observations of plant size. Climate covariates only vary by year, with no spatial variability within years. Thus, even if we fit models to individual-level data, we are missing the key interaction point between weather and individual plants [@Clark2011b] because all observations share the same climate covariates. Demographic studies should be designed with at least plot-level measurements of climate related variables (e.g., soil moisture). Second, accurately detecting climate signals will take even longer time series. Recent theoretical work on detecting climate signals in noisy data suggests that even advanced approaches to parameter fitting require 20-25 year time series [@Teller2016]. Third, ecologists need a stronger commitment to reporting uncertainty. Although most modeling studies explicitly consider model uncertainty, parameter uncertainty is often ignored. In some cases this is because the most convenient statistical methods make it difficult to propogate parameter uncertainty. Yet even Bayesian approaches that allow integration of model fitting and forecasting [@Hobbs2015] are not simple when using modeling approaches like integral projection models that separate the model fitting and simulation stages [@Rees2009]. However, as we have done here, it is still possible to include parameter uncertainty by drawing parameter values from MCMC iterations, taking care to draw all parameters from the same chain and iteration to account for their correlations. Only by being honest about our forecasts can we begin to produce better ones, and forecasts reported without parameter error are disingenuous.  Ignoring parameter error may be justifiable when the goal is investigating basic processes, but it is indefensible when forecasting is the goal.


Conclusions
-----------
This work is not a critique of density-structured population models. We are confident that density-structured models will prove to be a valuable tool for many applications. However, our analysis represents the first comparison, to our knowledge, of population models based on individual and aggregated forms of the same data in a climate change context. Our results confirm theoretical arguments [@Clark2011b] and empirical evidence [@Clark2011; @Clark2012] that individual responses are critical for predicting species' responses to climate change. It seems there is no short cut to producing accurate and precise population forecasts: we need detailed demographic data to forecast the impacts of climate change on populations. Given the importance of demographic data and its current collection cost, we need modern methods to collect demographic data more efficiently across environmental gradients in space and time.

Our results also offer a cautionary tale because forecast uncertainty was large for both model types. Even with 14 years of detailed demographic data and sophisticated modeling techniques, our projections contained too much uncertainty to be informative. Uncertainty in demographic responses to climate can be reduced by collecting (1) longer time series and (2) climate covariates that match the scale of inference (e.g., plot rather than landscape level climate/weather metrics). 
--->

Acknowledgments
---------------
This work was funded by the National Science Foundation through a Postdoctoral Research Fellowship in Biology to ATT (DBI-1400370) and a CAREER award to PBA (DEB-1054040). We thank the original mappers of the permanent quadrats in Montana and the digitizers in the Adler lab, without whom this work would not have been possible. Informal conversations with Stephen Ellner, Giles Hooker, Robin Snyder, and a series of meetings between the Adler and Weecology labs at USU sharpened our thinking. Brittany Teller provided comments that improved our manuscript. Compute, storage and other resources from the Division of Research Computing in the Office of Research and Graduate Studies at Utah State University are gratefully acknowledged.

\pagebreak{}


Tables
------
\begin{table}[ht]
\centering
\caption{Description of data.} 
\begin{tabular}{llrr}
  \hline
Species & Vital Rate Model & Num. Obs. & Num. Quadrats\\ 
  \hline
  \emph{B. gracilis} & Growth & 5670 & 29 \\ 
       & Survival & 10102 & 33 \\ 
       & Recruitment & 304 & 33 \\ 
       & Percent cover & 281 & 29 \\ 
  \rule{0pt}{3ex} \emph{H. comata} & Growth & 1990 & 16 \\ 
       & Survival & 3257 & 18 \\ 
       & Recruitment & 304 & 18 \\ 
       & Percent cover & 171 & 17 \\ 
  \rule{0pt}{3ex} \emph{P. smithii} & Growth & 8052 & 19 \\ 
       & Survival & 11344 & 19 \\ 
       & Recruitment & 304 & 19 \\ 
       & Percent cover & 217 & 19 \\ 
  \rule{0pt}{3ex} \emph{P. secunda} & Growth & 3018 & 18 \\ 
       & Survival & 4650 & 18 \\ 
       & Recruitment & 304 & 18 \\ 
       & Percent cover & 197 & 18 \\ 
   \hline
\end{tabular}
\end{table}


<!---
\begin{table}[ht]
\centering
\caption{Accuracy (mean absolute error, MAE) and precision (90\% Distance) 
                  of out of sample predictions. Forecasts were made without random 
                  year effects; only climate covariates could explain year-to-year 
                  variation. 90\% Distance refers to the average distance between the 
                  upper and lower 90th percentiles of the 100 predicted values for 
                  each quadrat-year combination.} 
\begin{tabular}{llrrr}
  \hline
Species & Model & MAE & 90\% Distance & Mean Obs. Cover \\ 
  \hline
BOGR & IPM & 4.61 & 22.41 & 8.26 \\ 
  BOGR & QBM & 4.06 & 29.18 & 8.26 \\ 
  HECO & IPM & 0.59 & 1.93 & 1.22 \\ 
  HECO & QBM & 0.60 & 5.64 & 1.22 \\ 
  PASM & IPM & 0.15 & 0.49 & 0.40 \\ 
  PASM & QBM & 0.20 & 1.59 & 0.40 \\ 
  POSE & IPM & 0.71 & 1.66 & 1.23 \\ 
  POSE & QBM & 0.76 & 3.52 & 1.23 \\ 
   \hline
\end{tabular}
\end{table}

\pagebreak{}
--->

\newpage{}

Figures
-------
```{r figure_1, dependson="plot-options", fig.cap="Time series of average percent cover over all quadrats for our four focal species: *Bouteloua gracilis* (BOGR), *Hesperostipa comata* (HECO), *Pascopyrum smithii* (PASM), and *Poa secunda* (POSE). Light grey lines show trajectories of individual quadrats. Note the different y-axis scales across panels.", fig.height=2, fig.width=8.5, eval=T}
library(ggthemes)
obs_data <- read.csv("../analysis/data_processing/speciesData/quadAllCover.csv")
#remove zeros for averaging
obs_data <- obs_data[which(obs_data$propCover>0),]
avgobs <- ddply(obs_data, .(year, Species), summarise,
                mean_cover = mean(propCover))

ggplot()+
  geom_line(data = obs_data, aes(x=(1900+year), y=propCover*100, group=quad), 
            color="grey", size=0.25)+
  geom_line(data=avgobs, aes(x=(1900+year), y=mean_cover*100))+
  geom_point(data=avgobs, aes(x=(1900+year), y=mean_cover*100),size=3)+
  ylab("Mean cover (%)")+
  xlab("Year")+
  theme_few()+
  facet_wrap("Species", ncol=4, nrow=1, scales = "free")+
  guides(shape=FALSE, linetype=FALSE)
```

\newpage{}

<!---
\begin{figure}[!ht]
  \centering
      \includegraphics[width=4in]{./components/micromeso_flowchart.png}
  \caption{Work flow of the data aggregation, model fitting, and population simulating.}
\end{figure}

\newpage{}


\begin{figure}[!ht]
  \centering
      \includegraphics[width=6in]{./components/lppds_suppfig.png}
  \caption{Cross validation scores (summed log pointwise predictive density) plotted against the prior variance for $\boldsymbol{\beta}_C$. The optimal score for prediction for each species-vital rate combination is shown with a vertical red line.}
\end{figure}

\newpage{}
--->
\begin{figure}[!ht]
  \centering
      \includegraphics[height=6in]{./components/forecast_accuracy_mockup.png}
  \caption{Comparison of one-step-ahead, out-of-sample forecast accuracy between the IPM and QBM models with and without the inclusion of climate covariates. Comparisons between equivalent IPM and QBM models indicate no significant difference in accuracy (\emph{P} > 0.05 for all comparisons). Likewise, including climate covariates did not result in siginificantly higher forecast accuracy (\emph{P} > 0.05 for all comparisons).}
\end{figure}

\newpage{}

\begin{figure}[!ht]
  \centering
      \includegraphics[height=7in]{./components/climate_posteriors_figure.png}
  \caption{Posterior distributions of climate effects ($\boldsymbol{\beta}_C$) for each species and vital rate statistical model. Since our priors were constrained via ridge-regression, we highlight climate effects whose 80\% credible intervals do not overlap zero (red for negative coefficients, blue for positive coefficients). Kernel bandwidths of posterior densities were adjusted by a factor of 4 for visual clarity.}
\end{figure}

\newpage{}

\begin{figure}[!ht]
  \centering
      \includegraphics[height=5in]{./components/forecast_horizon.png}
  \caption{The forecast horizons for both models. Points show the average accuracy ($\rho$) across all forecasts at a given time horizon.}
\end{figure}


\newpage{}

<!---
\begin{figure}[!ht]
  \centering
      \includegraphics[height=6in]{./components/climate_effect_corplots.png}
  \caption{Correlations between QBM and IPM estimates of climate effects. We ignore sizeXclimate interactions since these are not directly comparable across model types. The QBM does not have multiple vital rates, so its values are repeated across panels within each species. Across top panels, 'growth' = growth regression, 'rec' = recruitment regression, 'surv' = survival regression.}
\end{figure}

\newpage{}


\begin{figure}[!ht]
  \centering
      \includegraphics[height=6in]{./components/climate_change_results.png}
  \caption{Mean (points) and 90\% quantiles (errorbars) for the proportional difference between baseline simulations (using observed climate) and the climate pertubation simulation on the x-axis. We calculated proportional difference as log(perturbed climate cover) - log(observed climate cover), where 'perturbed' and 'observed' refer to the climate time series used to drive interannual variation in the simulations. Model error and parameter uncertainty were propagated through the simulation phase.}
\end{figure}

\pagebreak{}
--->

```{r figure_3, dependson="plot-options", fig.cap="Sensitivity of equilibrium cover simulated from the IPM to each climate scenario applied to individual and combined vital rates. For example, the points associated with G show the median cover from IPM simulations where a climate perturbation is applied only to the growth regression climate covariates. These simulations use mean parameter values for clarity.", fig.width=8, fig.height=6, cache=FALSE, results='hide', eval=F}
setwd("~/Repos/MicroMesoForecast/analysis/")

####
####  Make IPM sensitivity plot for lower panels
####
setwd("../analysis/ipm/simulations/results/climate_sensitivity/")
files <- list.files()
cover_files <- files[grep("cover", files)]
spp_id <- substr(cover_files, 1, 4)
num_files <- length(cover_files)
all_sims <- data.frame(time=NA, cover=NA, species=NA, climsim=NA, vital=NA)
for(i in 1:num_files){
  tmp <- read.csv(cover_files[i])
  tmp$species <- rep(spp_id[i], nrow(tmp))
  all_sims <- rbind(all_sims, tmp)
}
all_sims <- all_sims[2:nrow(all_sims),]

# Rename vital rates with codes
vital_names <- unique(all_sims$vital)
vital_codes <- c("A", "G", "GR", "GS", "R", "S" , "SR") 
vitals <- data.frame(names=vital_names,code=vital_codes)
for(vnow in vital_names){
  ids <- which(all_sims[,"vital"]==vnow)
  idcode <- which(vitals[,"names"]==vnow)
  all_sims[ids,"vital"] <- as.character(vitals[idcode,"code"])
}

# Rep the 'all' simulation for each vital rate for plotting
all_clim_sims <- subset(all_sims, vital=="A")
species <- unique(all_sims$species)
out_controls <- data.frame(time=NA, cover=NA, species=NA, climsim=NA, vital=NA)
for(spp in species){
  tmp <- subset(all_clim_sims, species==spp)
  for(vital in vital_codes){
    tmp$vital <- vital
    out_controls <- rbind(out_controls, tmp)
  }
}
out_controls <- out_controls[2:nrow(out_controls),]

# Combine the datasets
all_noclim_sims <- subset(all_sims, vital!="all")
final <- rbind(out_controls, all_noclim_sims)

# Calculate statistics for plotting
equilibrium_cover <- ddply(final, .(species, climsim, vital), summarise,
                           eq_cover = median(cover))
mean_cover <- ddply(subset(equilibrium_cover, climsim=="all"), .(species), summarise,
                    value = mean(eq_cover))


equilibrium_cover <- subset(equilibrium_cover, vital!="A")
bothid <- which(equilibrium_cover[,"climsim"]=="ppttemp")
equilibrium_cover[bothid,"climsim"] <- "zppttemp"
# myCols2 <- c("#277BA8", "#7ABBBD", "#AED77A")
sensplot <- ggplot(equilibrium_cover, aes(x=climsim, y=eq_cover*100, 
                              shape=vital, group=vital, linetype=vital))+
  geom_hline(data=mean_cover, aes(yintercept=value*100), linetype=2, color="grey45")+
  geom_line()+
  geom_point(size=4)+
  facet_wrap("species", scales = "free", ncol=2)+
  scale_linetype_discrete(name="Vital Rate")+
  scale_shape_discrete(name="Vital Rate")+
  scale_x_discrete(labels=c("baseline", "+ppt", "+temp", "+ppt&temp"))+
  ylab("Equilibrium Cover (%)")+
  xlab("Simulation")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

covertest <- subset(equilibrium_cover, climsim=="all")
colnames(covertest)[4] <- "obs_cover"
out <- merge(subset(equilibrium_cover, climsim!="all"), covertest[,c("species","vital","obs_cover")])
out$propdiff <- with(out, log(eq_cover*100)-log(obs_cover*100))

# meanparamplot <- grid.arrange(meanplot, sensplot, ncol=1, nrow=2)
# print(meanparamplot)
print(sensplot)

setwd("~/Repos/MicroMesoForecast/manuscript")
```

```{r figure_4, dependson="plot-options", fig.cap="Effect of quadrat sample size on the precision (standard deviation) of main climate effect estimates in the QBM. Increasing the number of quadrats results in diminishing returns in terms of parameter certainty. Light dashed lines show individual climate effects at five quadrat sample sizes. Thick dark lines are inverse gaussian fits showing the mean effect of increasing quadrat sample size on parameter precision.", fig.width=3, fig.height=7.5, cache=FALSE, results='hide', eval=F}
library(mgcv)

setwd("../analysis/quadBM/vitalRateRegressions/exclude_quad_test")

####
####  Read in model fits and summarize results
####
source("popgrowth_read_data.R")
spp <- unique(growD_all$Species)
num_quads <- numeric(length(spp))
for(i in 1:length(spp)){
  tmp <- subset(growD_all, Species==spp[i])
  num_quads[i] <- length(unique(tmp$quad))
}
num_quads <- as.data.frame(num_quads)
num_quads$species <- spp

all_files <- list.files("./results/")
all_fits <- data.frame(Parameter=NA, stddev=NA, id=NA, 
                       rmsquad=NA, rep=NA, species=NA)
for(i in 1:length(all_files)){
  tmp <- all_files[i]
  spp <- substring(tmp, 1, 4)
  qsrm1 <- unlist(strsplit(tmp, "[_]"))[2]
  qsrm <- gsub("numout", "", qsrm1)
  rep1 <- unlist(strsplit(tmp, "[_]"))[3]
  rep2 <- gsub(".RDS","",rep1)
  rep <- gsub("rep", "", rep2)
  
  long <- readRDS(paste("./results/",tmp, sep=""))
  short <- ddply(long, .(Parameter), summarise,
                 stddev = sd(value))
  climeff <- short[grep("b2", short$Parameter),]
  climeff$id <- substr(climeff$Parameter, 4, length(climeff$Parameter))
  climeff$id <- as.numeric(unlist(strsplit(climeff$id, split=']')))  
  climeff <- climeff[with(climeff, order(id)),]
  climeff$rmsquad <- qsrm
  climeff$rep <- rep
  climeff$species <- spp
  all_fits <- rbind(all_fits, climeff)
} # end file loop

all_fits <- all_fits[2:nrow(all_fits),]

####
####  Read in full fits
####
dir <- "../truncNormModel/"
files <- list.files(dir)
files <- files[grep(".RDS", files)]
all_alls <- data.frame(Parameter=NA, stddev=NA, id=NA, 
                       rmsquad=NA, rep=NA, species=NA)
for(i in 1:length(files)){
  tmp <- files[i]
  spp1 <- unlist(strsplit(tmp, "[_]"))[3]
  spp <- gsub(".RDS","",spp1)
  
  long <- readRDS(paste(dir,tmp, sep=""))
  short <- ddply(long, .(Parameter), summarise,
                 stddev = sd(value))
  climeff <- short[grep("b2", short$Parameter),]
  climeff$id <- substr(climeff$Parameter, 4, length(climeff$Parameter))
  climeff$id <- as.numeric(unlist(strsplit(climeff$id, split=']')))  
  climeff <- climeff[with(climeff, order(id)),]
  climeff$rmsquad <- 0
  climeff$rep <- 1
  climeff$species <- spp
  all_alls <- rbind(all_alls, climeff)
}
all_alls <- all_alls[2:nrow(all_alls),]

####
####  Aggregate results by species and rep
####
all_fits <- rbind(all_fits, all_alls)
agg_fits <- ddply(all_fits, .(Parameter, rmsquad, species, id), summarise,
                  avg_stddev = mean(stddev))
agg_fits2 <- agg_fits[which(agg_fits$id %in% c(1:5)),]
agg_fits2 <- merge(agg_fits2, num_quads, by="species")
agg_fits2$quadsfit <- with(agg_fits2, num_quads-as.numeric(rmsquad))


####
####  Fit model (need to do by species)
####
modBOGR <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="BOGR"),
               family=quasi(link="1/mu^2"))
modHECO <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="HECO"),
               family=quasi(link="1/mu^2"))
modPASM <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="PASM"),
               family=quasi(link="1/mu^2"))
modPOSE <- gam(avg_stddev~quadsfit, data=subset(agg_fits2, species=="POSE"),
               family=quasi(link="1/mu^2"))
summary(modBOGR)
summary(modHECO)
summary(modPASM)
summary(modPOSE)


####
#### Plot
####
ggplot(agg_fits2, aes(x=quadsfit, y=avg_stddev))+
  geom_line(aes(group=Parameter), alpha=0.3, linetype=2)+
  geom_point(aes(group=Parameter), alpha=0.3, size=3)+
#   stat_smooth(method="loess", size=2, color="black", se=FALSE)+
  geom_smooth(method="glm", formula=y~x, family=quasi(link="1/mu^2"),
              size=2, color="black", se=FALSE)+
  facet_wrap("species", scales = "free", ncol=1)+
  theme_bw()+
  xlab("Number of quadrats fit")+
  ylab("Standard deviation of coefficient")


```


\singlespace{}

References
----------
